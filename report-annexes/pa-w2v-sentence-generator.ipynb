{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn on Auto-Complete\n",
    "%config IPCompleter.greedy=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start logging process at root level\n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "logging.root.setLevel(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model and dictionary\n",
    "model_path =\"models/wiki-en-190409-s300-w5-mc1-bw10000-cbow-i5-c10-unlem.model\"\n",
    "dictionary_path = \"dictionaries/enwiki-20190409-dict-unlemmatized.txt.bz2\"\n",
    "is_lemmatized = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-05-09 19:10:49,507 : INFO : 'pattern' package found; tag filters are available for English\n",
      "2019-05-09 19:10:49,518 : INFO : loading Word2Vec object from models/wiki-en-190409-s300-w5-mc1-bw10000-cbow-i5-c10-unlem.model\n",
      "2019-05-09 19:11:49,686 : INFO : loading wv recursively from models/wiki-en-190409-s300-w5-mc1-bw10000-cbow-i5-c10-unlem.model.wv.* with mmap=r\n",
      "2019-05-09 19:11:49,689 : INFO : loading vectors from models/wiki-en-190409-s300-w5-mc1-bw10000-cbow-i5-c10-unlem.model.wv.vectors.npy with mmap=r\n",
      "2019-05-09 19:11:49,693 : INFO : setting ignored attribute vectors_norm to None\n",
      "2019-05-09 19:11:49,697 : INFO : loading vocabulary recursively from models/wiki-en-190409-s300-w5-mc1-bw10000-cbow-i5-c10-unlem.model.vocabulary.* with mmap=r\n",
      "2019-05-09 19:11:49,699 : INFO : loading trainables recursively from models/wiki-en-190409-s300-w5-mc1-bw10000-cbow-i5-c10-unlem.model.trainables.* with mmap=r\n",
      "2019-05-09 19:11:49,700 : INFO : loading syn1neg from models/wiki-en-190409-s300-w5-mc1-bw10000-cbow-i5-c10-unlem.model.trainables.syn1neg.npy with mmap=r\n",
      "2019-05-09 19:11:49,703 : INFO : setting ignored attribute cum_table to None\n",
      "2019-05-09 19:11:49,704 : INFO : loaded models/wiki-en-190409-s300-w5-mc1-bw10000-cbow-i5-c10-unlem.model\n"
     ]
    }
   ],
   "source": [
    "# Load word2vec unlemmatized model\n",
    "from gensim.models import Word2Vec\n",
    "model = Word2Vec.load(model_path, mmap='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving some ram by using the KeyedVectors instance\n",
    "wv = model.wv\n",
    "#del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.utils import simple_preprocess\n",
    "import numpy as np\n",
    "\n",
    "def tokemmized(sentence, vocabulary):\n",
    "    return np.array([word for word in simple_preprocess(sentence) if word in vocabulary])\n",
    "\n",
    "def compute_sentence_similarity(sentence_1, sentence_2):\n",
    "    vocabulary = set(model.wv.index2word)\n",
    "    tokens_1 = tokemmized(sentence_1, vocabulary)\n",
    "    tokens_2 = tokemmized(sentence_2, vocabulary)\n",
    "    del vocabulary\n",
    "    print(tokens_1, tokens_2)\n",
    "    return wv.n_similarity(tokens_1, tokens_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['this' 'is' 'sentence'] ['this' 'is' 'also' 'sentence']\n",
      "0.9266693658411185 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "s1 = 'This room is dirty'\n",
    "s2 = 'dirty and disgusting room'\n",
    "\n",
    "s1 = 'this is a sentence'\n",
    "s2 ='this is also a sentence'\n",
    "\n",
    "#from gensim import utils\n",
    "#print(utils.lemmatize(\"The quick brown fox jumps over the lazy dog.\"))\n",
    "#print(utils.lemmatize(s1))\n",
    "\n",
    "similarity = compute_sentence_similarity(s1, s2)\n",
    "print(similarity,\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Translate a string\n",
    "vocabulary = set(model.wv.index2word)\n",
    "#del vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "def add_vectors(vector_1, vector_2):\n",
    "    return vector_1 + vector_2 if(vector_1.shape == vector_2.shape) else None\n",
    "\n",
    "\n",
    "vec_random_1 = np.random.rand(2,)\n",
    "vec_random_2 = np.random.rand(1,)\n",
    "\n",
    "print(add_vectors(vec_random_1,vec_random_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_sentence(sentence, vector, operation, verbose=False):\n",
    "    tokens = tokemmized(sentence, vocabulary)\n",
    "    #print(operation(tokens,tokens))\n",
    "    #print(tokens.shape)\n",
    "    if verbose: print(tokens,\"\\n\")\n",
    "    #print(vector)\n",
    "    #print(np.array([wv.word_vec(token) for token in tokens]))\n",
    "    #print(np.array([wv.word_vec(token, use_norm=False) for token in tokens]))\n",
    "    \n",
    "    sentence_vector = np.array([wv.word_vec(token, use_norm=False) for token in tokens])\n",
    "    normed_sentence_vector = np.array(sentence_vector / np.linalg.norm(sentence_vector))\n",
    "    normed_vector = np.array(vector / np.linalg.norm(vector))\n",
    "    \n",
    "    #print(sentence_vector)\n",
    "    #print(normed_vector)\n",
    "    #tokens_vector = np.array([my_vector+normed_vector for my_vector in sentence_vector])\n",
    "    #print(tokens_vector.shape)\n",
    "    \n",
    "    generated_sentence = []\n",
    "    if verbose: print(wv.most_similar(positive=[normed_vector]),\"\\n\")\n",
    "    for token_id in range(len(normed_sentence_vector)):\n",
    "        #print(token_id)\n",
    "        output = normed_sentence_vector[token_id]+normed_vector[token_id]\n",
    "        #print(output)\n",
    "        if verbose: print(wv.most_similar(positive=[normed_sentence_vector[token_id]]))\n",
    "        if verbose: print(wv.most_similar(positive=[output]))\n",
    "        if verbose: print(\"\\n\")\n",
    "        #print(model.wv.most_similar(positive=[tokens_vector[0]]))\n",
    "        #wv.most_similar([model.wv.word_vec['capital'] + model.wv.word_vec['science']])\n",
    "        generated_sentence.append(wv.most_similar(positive=[output], topn=1)[0][0])\n",
    "        #print(generated_sentence)\n",
    "        \n",
    "    return generated_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def get_random_word(vocabulary):\n",
    "#    np.random.choice(vocabulary, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('king', 0.9372287392616272), ('queen', 0.6690690517425537), ('prince', 0.6481649875640869), ('kings', 0.5768133401870728), ('emperor', 0.5275021195411682), ('monarch', 0.5215415954589844), ('princess', 0.5091894268989563), ('crown', 0.4927079379558563), ('throne', 0.4920075535774231), ('vi', 0.482151061296463)] \n",
      "\n",
      "['this', 'convinced', 'sentence']\n",
      "[('knocknaskeharoe', 0.2645658850669861), ('incom', 0.2635432481765747), ('neshwille', 0.262343168258667), ('cravedi', 0.2608887851238251), ('harmful', 0.25984159111976624), ('saenchuanglek', 0.25976353883743286), ('accidentaltrap', 0.2591168284416199), ('styland', 0.257991760969162), ('complementary', 0.2571954131126404), ('maternalistic', 0.255767285823822)] \n",
      "\n",
      "['this', 'is', 'sentence']\n",
      "[('king', 0.8530193567276001), ('prince', 0.5861936807632446), ('queen', 0.5642796158790588), ('kings', 0.5384057760238647), ('monarch', 0.501059889793396), ('lord', 0.4709792733192444), ('aethelred', 0.4706173241138458), ('ruler', 0.4685106873512268), ('ethelred', 0.46632906794548035), ('duke', 0.46218642592430115)] \n",
      "\n",
      "['this', 'convinced', 'danceworks']\n",
      "[('اشتباه', 0.30970412492752075), ('vācissara', 0.29018083214759827), ('bobtails', 0.28184133768081665), ('khodavandane', 0.28162702918052673), ('nāsru', 0.27162158489227295), ('sýrie', 0.2707415223121643), ('aybengir', 0.2702402174472809), ('sāmik', 0.27020853757858276), ('rāmarasam', 0.2692358195781708), ('áqá', 0.26731109619140625)] \n",
      "\n",
      "['this', 'convinced', 'danceworks']\n",
      "[('king', 0.8441299200057983), ('queen', 0.5206315517425537), ('prince', 0.5197598934173584), ('kings', 0.47947773337364197), ('lord', 0.4696161448955536), ('duke', 0.46795520186424255), ('monarch', 0.4610660970211029), ('emperor', 0.4573044180870056), ('ethelred', 0.45627057552337646), ('throne', 0.4436478316783905)] \n",
      "\n",
      "['this', 'convinced', 'danceworks']\n"
     ]
    }
   ],
   "source": [
    "#print(translate_sentence(s1, np.random.rand(300,)*np.random.rand(300,),add_vectors,verbose=False))\n",
    "print(translate_sentence(s1, np.random.rand(300,)+wv[\"king\"],add_vectors,verbose=False),\"\\n\")\n",
    "print(translate_sentence(s1, np.random.rand(300,)-wv[\"king\"],add_vectors,verbose=False),\"\\n\")\n",
    "print(translate_sentence(s1, np.random.rand(300,)*wv[\"king\"],add_vectors,verbose=False),\"\\n\")\n",
    "print(translate_sentence(s1, np.random.rand(300,)/wv[\"king\"],add_vectors,verbose=False),\"\\n\")\n",
    "print(translate_sentence(s1, np.random.rand(300,)%wv[\"king\"],add_vectors,verbose=False),\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(translate_sentence(s1, np.random.rand(300,)*np.random.rand(300,),add_vectors,verbose=False))\n",
    "#print(translate_sentence(s1, np.random.rand(300,)+wv[\"king\"],add_vectors,verbose=False),\"\\n\")\n",
    "#print(translate_sentence(s1, np.random.rand(300,)-wv[\"king\"],add_vectors,verbose=False),\"\\n\")\n",
    "#print(translate_sentence(s1, np.random.rand(300,)*wv[\"king\"],add_vectors,verbose=False),\"\\n\")\n",
    "#print(translate_sentence(s1, np.random.rand(300,)/wv[\"king\"],add_vectors,verbose=False),\"\\n\")\n",
    "#print(translate_sentence(s1, np.random.rand(300,)%wv[\"king\"],add_vectors,verbose=False),\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('king', 0.9999999403953552), ('queen', 0.6651210784912109), ('prince', 0.6620543599128723), ('kings', 0.60276198387146), ('emperor', 0.5582844614982605), ('monarch', 0.5439431667327881), ('throne', 0.5276303291320801), ('duke', 0.509221613407135), ('crown', 0.508944034576416), ('ruler', 0.5062711238861084)] \n",
      "\n",
      "['this', 'convinced', 'danceworks'] \n",
      "\n",
      "[('science', 0.9999999403953552), ('sciences', 0.7399516105651855), ('physics', 0.6375185251235962), ('biology', 0.6136776208877563), ('neuroscience', 0.6047805547714233), ('informatics', 0.6037142276763916), ('humanities', 0.603361964225769), ('biotechnology', 0.598221480846405), ('mathematics', 0.5930382013320923), ('microbiology', 0.5862153768539429)] \n",
      "\n",
      "['this', 'convinced', 'sentence'] \n",
      "\n",
      "[('dog', 1.0), ('dogs', 0.7544571161270142), ('cat', 0.7354434728622437), ('puppy', 0.6880403161048889), ('dachshund', 0.682579517364502), ('rabbit', 0.6537305116653442), ('rottweiler', 0.6467593908309937), ('poodle', 0.6438148021697998), ('pig', 0.6335182189941406), ('hound', 0.6029298305511475)] \n",
      "\n",
      "['attended', 'is', 'sentence'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(translate_sentence(s1, wv[\"king\"],add_vectors,verbose=False),\"\\n\")\n",
    "print(translate_sentence(s1, wv[\"science\"],add_vectors,verbose=False),\"\\n\")\n",
    "print(translate_sentence(s1, wv[\"dog\"],add_vectors,verbose=False),\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('feminique', 0.2670329213142395), ('gawding', 0.26683396100997925), ('mystic羽黒妖', 0.2648448646068573), ('portoverde', 0.2600330114364624), ('perdóndaris', 0.25431621074676514), ('mahagedera', 0.2524976134300232), ('佐藤義清', 0.2509377896785736), ('akame', 0.2507975995540619), ('wealds', 0.2503069341182709), ('eijigoroshi', 0.2493540197610855)] \n",
      "\n",
      "['capital', 'of', 'science'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "sentence = \"Capital of science\"\n",
    "print(translate_sentence(sentence, np.random.rand(300,)*np.random.rand(300,)+10*np.random.rand(300,),add_vectors,verbose=False),\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('dog', 1.0), ('dogs', 0.7544571161270142), ('cat', 0.7354434728622437), ('puppy', 0.6880403161048889), ('dachshund', 0.682579517364502), ('rabbit', 0.6537305116653442), ('rottweiler', 0.6467593908309937), ('poodle', 0.6438148021697998), ('pig', 0.6335182189941406), ('hound', 0.6029298305511475)] \n",
      "\n",
      "['annie', 'of', 'science'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "sentence = \"Capital of science\"\n",
    "print(translate_sentence(sentence, wv[\"dog\"],add_vectors,verbose=False),\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('science', 0.9999999403953552), ('sciences', 0.7399516105651855), ('physics', 0.6375185251235962), ('biology', 0.6136776208877563), ('neuroscience', 0.6047805547714233), ('informatics', 0.6037142276763916), ('humanities', 0.603361964225769), ('biotechnology', 0.598221480846405), ('mathematics', 0.5930382013320923), ('microbiology', 0.5862153768539429)] \n",
      "\n",
      "['town', 'tetlow', 'city', 'that', 'convinced', 'the', 'overwhelm', 'seat', 'of', 'lovestruck', 'in', 'political', 'hamutumbangela', 'such', 'as', 'cheeky', 'or', 'tiring'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#definition of capital\n",
    "sentence = \"A town or city that is the official seat of government in a political entity, such as a state or nation.\"\n",
    "print(translate_sentence(sentence, wv[\"science\"],add_vectors,verbose=False),\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('science', 0.9999999403953552), ('sciences', 0.7399516105651855), ('physics', 0.6375185251235962), ('biology', 0.6136776208877563), ('neuroscience', 0.6047805547714233), ('informatics', 0.6037142276763916), ('humanities', 0.603361964225769), ('biotechnology', 0.598221480846405), ('mathematics', 0.5930382013320923), ('microbiology', 0.5862153768539429)] \n",
      "\n",
      "['the', 'fallenbrunnen', 'capital', 'of', 'attended', 'world', 'convinced', 'wall', 'street'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "sentence = \"the financial capital of the world is wall street\"\n",
    "print(translate_sentence(sentence, wv[\"science\"],add_vectors,verbose=False),\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['gawding', 'financial', 'capital', 'gawding', 'the', 'world', 'is', 'wall', 'street'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "sentence = \"the financial capital of the world is wall street\"\n",
    "print(translate_sentence(sentence, wv[\"science\"],add_vectors,verbose=False),\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('黒松駅', 0.9640800952911377), ('黒松内駅', 0.9301100969314575), ('たかた', 0.9295684099197388), ('yakimaki', 0.9279204607009888), ('くろまつない', 0.9275338649749756), ('azamui', 0.9215079545974731), ('佐野のわたし駅', 0.9212697744369507), ('onoppunai', 0.921174168586731), ('たかはま', 0.9211598038673401), ('高田駅', 0.9198777675628662)] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "random_vector = np.random.choice(np.array(list(vocabulary)))\n",
    "print(wv.most_similar(positive=[random_vector]),\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the', 'fallenbrunnen', 'annie', 'recalled', 'the', 'world', 'is', 'wall', 'street'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "sentence = \"the financial capital of the world is wall street\"\n",
    "print(translate_sentence(sentence, wv[np.random.choice(np.array(list(vocabulary)))],add_vectors,verbose=False),\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('talgo', 0.4247443675994873), ('renfe', 0.4004928171634674), ('feve', 0.3839436173439026), ('ocamlfind', 0.3784955143928528), ('milucho', 0.37699535489082336), ('enasa', 0.37661993503570557), ('bonaplata', 0.3707815706729889), ('acciona', 0.369507372379303), ('navantia', 0.36491289734840393), ('ferrovial', 0.36447039246559143)] \n",
      "\n",
      "['attended', 'financial', 'capital', 'recalled', 'attended', 'world', 'convinced', 'urbanathlon', 'nabiago'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "sentence = \"the financial capital of the world is wall street\"\n",
    "my_random_vector = np.random.choice(np.array(list(vocabulary)))\n",
    "print(wv.most_similar(positive=[my_random_vector]),\"\\n\")\n",
    "print(translate_sentence(sentence, wv[my_random_vector],add_vectors,verbose=False),\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('dog', 1.0), ('dogs', 0.7544571161270142), ('cat', 0.7354434728622437), ('puppy', 0.6880403161048889), ('dachshund', 0.682579517364502), ('rabbit', 0.6537305116653442), ('rottweiler', 0.6467593908309937), ('poodle', 0.6438148021697998), ('pig', 0.6335182189941406), ('hound', 0.6029298305511475)] \n",
      "\n",
      "['snobbishness', 'wrongs', 'don', 'make', 'meritoriois'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#https://www.phrasemix.com/collections/the-50-most-important-english-proverbs\n",
    "print(translate_sentence(\"Two wrongs don't make a right.\", wv[random_vector],add_vectors,verbose=False),\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('dog', 1.0), ('dogs', 0.7544571161270142), ('cat', 0.7354434728622437), ('puppy', 0.6880403161048889), ('dachshund', 0.682579517364502), ('rabbit', 0.6537305116653442), ('rottweiler', 0.6467593908309937), ('poodle', 0.6438148021697998), ('pig', 0.6335182189941406), ('hound', 0.6029298305511475)] \n",
      "\n",
      "['attended', 'pen', 'is', 'mightier', 'anaharlick', 'attended', 'sword'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(translate_sentence(\"The pen is mightier than the sword.\", wv[random_vector],add_vectors,verbose=False),\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('dog', 1.0), ('dogs', 0.7544571161270142), ('cat', 0.7354434728622437), ('puppy', 0.6880403161048889), ('dachshund', 0.682579517364502), ('rabbit', 0.6537305116653442), ('rottweiler', 0.6467593908309937), ('poodle', 0.6438148021697998), ('pig', 0.6335182189941406), ('hound', 0.6029298305511475)] \n",
      "\n",
      "['serves', 'in', 'rome', 'do', 'appealed', 'attended', 'romans'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(translate_sentence(\"When in Rome, do as the Romans.\", wv[random_vector],add_vectors,verbose=False),\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('dog', 1.0), ('dogs', 0.7544571161270142), ('cat', 0.7354434728622437), ('puppy', 0.6880403161048889), ('dachshund', 0.682579517364502), ('rabbit', 0.6537305116653442), ('rottweiler', 0.6467593908309937), ('poodle', 0.6438148021697998), ('pig', 0.6335182189941406), ('hound', 0.6029298305511475)] \n",
      "\n",
      "['attended', 'squeaky', 'wheel', 'gets', 'attended', 'nanzan'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(translate_sentence(\"The squeaky wheel gets the grease.\", wv[random_vector],add_vectors,verbose=False),\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('dog', 1.0), ('dogs', 0.7544571161270142), ('cat', 0.7354434728622437), ('puppy', 0.6880403161048889), ('dachshund', 0.682579517364502), ('rabbit', 0.6537305116653442), ('rottweiler', 0.6467593908309937), ('poodle', 0.6438148021697998), ('pig', 0.6335182189941406), ('hound', 0.6029298305511475)] \n",
      "\n",
      "['serves', 'the', 'going', 'gets', 'treferig', 'attended', 'tough', 'founded', 'пехарник'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "sentence = \"When the going gets tough, the tough get going.\"\n",
    "print(translate_sentence(sentence, wv[random_vector],add_vectors,verbose=False),\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('dog', 1.0), ('dogs', 0.7544571161270142), ('cat', 0.7354434728622437), ('puppy', 0.6880403161048889), ('dachshund', 0.682579517364502), ('rabbit', 0.6537305116653442), ('rottweiler', 0.6467593908309937), ('poodle', 0.6438148021697998), ('pig', 0.6335182189941406), ('hound', 0.6029298305511475)] \n",
      "\n",
      "['umuokiri', 'man', 'is', 'an', 'xylochaerus'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "sentence = \"No man is an island.\"\n",
    "print(translate_sentence(sentence, wv[random_vector],add_vectors,verbose=False),\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('dog', 1.0), ('dogs', 0.7544571161270142), ('cat', 0.7354434728622437), ('puppy', 0.6880403161048889), ('dachshund', 0.682579517364502), ('rabbit', 0.6537305116653442), ('rottweiler', 0.6467593908309937), ('poodle', 0.6438148021697998), ('pig', 0.6335182189941406), ('hound', 0.6029298305511475)] \n",
      "\n",
      "['rccs', 'favors', 'the', 'bold'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "sentence = \"Fortune favors the bold.\"\n",
    "print(translate_sentence(sentence, wv[random_vector],add_vectors,verbose=False),\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('dog', 1.0), ('dogs', 0.7544571161270142), ('cat', 0.7354434728622437), ('puppy', 0.6880403161048889), ('dachshund', 0.682579517364502), ('rabbit', 0.6537305116653442), ('rottweiler', 0.6467593908309937), ('poodle', 0.6438148021697998), ('pig', 0.6335182189941406), ('hound', 0.6029298305511475)] \n",
      "\n",
      "['lorrey', 'who', 'live', 'in', 'yrrl', 'ragone', 'should', 'attended', 'postindustrial', 'stones'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "sentence = \"People who live in glass houses should not throw stones.\"\n",
    "print(translate_sentence(sentence, wv[random_vector],add_vectors,verbose=False),\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('dog', 1.0), ('dogs', 0.7544571161270142), ('cat', 0.7354434728622437), ('puppy', 0.6880403161048889), ('dachshund', 0.682579517364502), ('rabbit', 0.6537305116653442), ('rottweiler', 0.6467593908309937), ('poodle', 0.6438148021697998), ('pig', 0.6335182189941406), ('hound', 0.6029298305511475)] \n",
      "\n",
      "['crystengcomm', 'for', 'the', 'best', 'attended', 'murmelschwein', 'for', 'attended', 'maṇikaśrījñāna'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "sentence = \"Hope for the best, but prepare for the worst.\"\n",
    "print(translate_sentence(sentence, wv[random_vector],add_vectors,verbose=False),\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('dog', 1.0), ('dogs', 0.7544571161270142), ('cat', 0.7354434728622437), ('puppy', 0.6880403161048889), ('dachshund', 0.682579517364502), ('rabbit', 0.6537305116653442), ('rottweiler', 0.6467593908309937), ('poodle', 0.6438148021697998), ('pig', 0.6335182189941406), ('hound', 0.6029298305511475)] \n",
      "\n",
      "['kitchissipi', 'late', 'than', 'never'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "sentence = \"Better late than never.\"\n",
    "print(translate_sentence(sentence, wv[random_vector],add_vectors,verbose=False),\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('dog', 1.0), ('dogs', 0.7544571161270142), ('cat', 0.7354434728622437), ('puppy', 0.6880403161048889), ('dachshund', 0.682579517364502), ('rabbit', 0.6537305116653442), ('rottweiler', 0.6467593908309937), ('poodle', 0.6438148021697998), ('pig', 0.6335182189941406), ('hound', 0.6029298305511475)] \n",
      "\n",
      "['osostolus', 'of', 'feather', 'flock', 'extortionary'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "sentence = \"Birds of a feather flock together.\"\n",
    "print(translate_sentence(sentence, wv[random_vector],add_vectors,verbose=False),\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('dog', 1.0), ('dogs', 0.7544571161270142), ('cat', 0.7354434728622437), ('puppy', 0.6880403161048889), ('dachshund', 0.682579517364502), ('rabbit', 0.6537305116653442), ('rottweiler', 0.6467593908309937), ('poodle', 0.6438148021697998), ('pig', 0.6335182189941406), ('hound', 0.6029298305511475)] \n",
      "\n",
      "['scholar', 'your', 'friends', 'close', 'recalled', 'pulaman', 'enemies', 'frankalmoinage'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "sentence = \"Keep your friends close and your enemies closer.\"\n",
    "print(translate_sentence(sentence, wv[random_vector],add_vectors,verbose=False),\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('dog', 1.0), ('dogs', 0.7544571161270142), ('cat', 0.7354434728622437), ('puppy', 0.6880403161048889), ('dachshund', 0.682579517364502), ('rabbit', 0.6537305116653442), ('rottweiler', 0.6467593908309937), ('poodle', 0.6438148021697998), ('pig', 0.6335182189941406), ('hound', 0.6029298305511475)] \n",
      "\n",
      "['mobilized', 'is', 'worth', 'thousand', 'звениговский'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "sentence = \"A picture is worth a thousand words.\"\n",
    "print(translate_sentence(sentence, wv[random_vector],add_vectors,verbose=False),\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('dog', 1.0), ('dogs', 0.7544571161270142), ('cat', 0.7354434728622437), ('puppy', 0.6880403161048889), ('dachshund', 0.682579517364502), ('rabbit', 0.6537305116653442), ('rottweiler', 0.6467593908309937), ('poodle', 0.6438148021697998), ('pig', 0.6335182189941406), ('hound', 0.6029298305511475)] \n",
      "\n",
      "['mmcaa', 'no', 'such', 'thing', 'appealed', 'wurznbacher', 'lunch'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "sentence = \"There's no such thing as a free lunch.\"\n",
    "print(translate_sentence(sentence, wv[random_vector],add_vectors,verbose=False),\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['there', 'no', 'place', 'like', 'home'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "sentence = \"There's no place like home.\"\n",
    "print(translate_sentence(sentence, wv[\"yellow\"],add_vectors,verbose=False),\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Man is to Woman what King is to ?\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('switzerland', 0.6374906301498413),\n",
       " ('gälltofta', 0.4903566241264343),\n",
       " ('dubendorf', 0.48968037962913513),\n",
       " ('pratteln', 0.45561110973358154),\n",
       " ('notwil', 0.44998636841773987),\n",
       " ('dzhirkvelov', 0.44828879833221436),\n",
       " ('futuresgeneva', 0.44405433535575867),\n",
       " ('nottwil', 0.43685224652290344),\n",
       " ('gruyeres', 0.4326044023036957),\n",
       " ('macolin', 0.4323049783706665)]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Man is to Woman what King is to ?\")\n",
    "wv.most_similar([wv['wallstreet'] - wv['finance'] + wv['switzerland']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py36]",
   "language": "python",
   "name": "conda-env-py36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
