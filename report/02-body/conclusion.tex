% ---------------------------------------------------------------------
% Cloned from the HES-SO//Master canvas 2019
% ---------------------------------------------------------------------
\chapter{Conclusion}
\label{chap:conclusion}
During this \gls{dp}, much knowledge has been acquired by the author via Research and Experimentation. This section is meant to summarise and conclude the 180 hours over 15 weeks allocated for this project.

\section{\gls{dp}}
As expected, the initial plan [\ref{plan:initial}] was not followed. However, the effective plan [\ref{plan:effective}] resulted in a project focusing on the Word Embedding concept, and more specifically, the Word2Vec technic. Indeed, taking a step back on the 15 weeks spent on the project, the way that the \gls{dp} is designed, the project was meant to go in this direction. Hours are flying during research and experimentation, and unexpected situations are part of the game when working with unknown technologies.

\subsection{Results}
The outcome of the project can be summarized as follow:

\begin{itemize}
\setlength\itemsep{0em}
    \item The author gained expertise into the Word Embedding field, and the Word2Vec technic.
    \item A research-oriented document has been produced.
    \item Experiments have been implemented.
\end{itemize}


\subsection{Time spent}
The initial naive plan to split the required 180 hours across the 15 weeks was to perform 12 hours per week. The effective hours sums up to 191h. A delta of 11h is fairly acceptable for a semester project. It is difficult to not regret of not providing more hours into the \gls{dp}, but the workload of other classes is not providing many flexibilities.

\begin{itemize}
\setlength\itemsep{0em}
    \item Research: 72h
    \item Development: 48h
    \item Meeting: 11h
    \item Redaction: 60h
\end{itemize}


\section{Objectives}
As a wrap up, let's conclude on the red line [\ref{questions:redline}].

\subsection{Word Embedding: Word2Vec}
Using the Gensim Framework, the author was able to experiment and understand the Word2Vec technic with details. The difficulties encountered while building his own Wikipedia model forced to dive into the technicalities related to the nature of how Word2Vec works, which increased the expertise and resulted in state of the art solutions.

\subsection{Word2Vec Chatbots}
Making Word2Vec only chatbots is not possible; however the output model is already used in advanced \gls{dl} chatbots using LSTM or even Transformers [\ref{sota:contextual-embedding}]. Word Embedding provides the foundation for the next generation chatbots with Thought Embedding, getting every step closer to the General Chatbots [\ref{sota:chatbots-general}].


\subsection{Word2Vec for Proactivity}
Proactivity as explored in this \gls{dp} is not able to provide proactivity only based on the Word2Vec technic. Indeed, more experiments must be done in order to be convinced of its feasibility. An idea of a solution has been briefly described with abstract analogies [\ref{experiment:abstract-analogies}], which could provide an indirect layer of abstraction while staying with Word2Vec low-level operations.


%\newpage
~\\[5cm]
\Locality, \Date
~\\[1cm]
\Author