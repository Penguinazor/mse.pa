{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn on Auto-Complete\n",
    "%config IPCompleter.greedy=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start logging process at root level\n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "logging.root.setLevel(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model and dictionary\n",
    "#model_id_current = 99999\n",
    "#model_path_current = \"models/enwiki-full-dict-\"+str(model_id_current)+\".model\"\n",
    "#model_path_99999 = \"models/enwiki-20190319-lemmatized-99999.model\"\n",
    "model_path_current =\"models/enwiki-20190409-unlemmatized.model\"\n",
    "\n",
    "dictionary_full_wikien_lem_path = \"dictionaries/enwiki-20190409-dict-unlemmatized.txt.bz2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-04-23 12:55:31,926 : INFO : 'pattern' package found; tag filters are available for English\n",
      "2019-04-23 12:55:31,935 : INFO : loading Word2Vec object from models/enwiki-20190409-unlemmatized.model\n",
      "2019-04-23 12:56:26,021 : INFO : loading wv recursively from models/enwiki-20190409-unlemmatized.model.wv.* with mmap=r\n",
      "2019-04-23 12:56:26,024 : INFO : loading vectors from models/enwiki-20190409-unlemmatized.model.wv.vectors.npy with mmap=r\n",
      "2019-04-23 12:56:26,046 : INFO : setting ignored attribute vectors_norm to None\n",
      "2019-04-23 12:56:26,049 : INFO : loading vocabulary recursively from models/enwiki-20190409-unlemmatized.model.vocabulary.* with mmap=r\n",
      "2019-04-23 12:56:26,051 : INFO : loading trainables recursively from models/enwiki-20190409-unlemmatized.model.trainables.* with mmap=r\n",
      "2019-04-23 12:56:26,053 : INFO : loading syn1neg from models/enwiki-20190409-unlemmatized.model.trainables.syn1neg.npy with mmap=r\n",
      "2019-04-23 12:56:26,083 : INFO : setting ignored attribute cum_table to None\n",
      "2019-04-23 12:56:26,085 : INFO : loaded models/enwiki-20190409-unlemmatized.model\n"
     ]
    }
   ],
   "source": [
    "# Load word2vec unlemmatized model\n",
    "from gensim.models import Word2Vec\n",
    "model = Word2Vec.load(model_path_current, mmap='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dog/NN\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Custom lemmatizer function to play with word\n",
    "from gensim.utils import lemmatize\n",
    "#vocabulary = set(wv.index2word)\n",
    "def lem(word):\n",
    "    try:\n",
    "        return lemmatize(word)[0].decode(\"utf-8\")\n",
    "    except:\n",
    "        pass\n",
    "        \n",
    "print(lem(\"dog\"))\n",
    "print(lem(\"that\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-04-23 12:57:13,947 : INFO : precomputing L2-norms of word weight vectors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most similar to woman\n",
      "[('girl', 0.7156134247779846), ('man', 0.7035340070724487), ('person', 0.627473771572113), ('prostitute', 0.5917390584945679), ('divorcee', 0.5554578900337219), ('divorcée', 0.5542126893997192), ('policewoman', 0.5420450568199158), ('seductress', 0.5387763381004333), ('housewife', 0.535172164440155), ('frenchwoman', 0.5283711552619934)]\n"
     ]
    }
   ],
   "source": [
    "# Testing similarity\n",
    "print(\"Most similar to\",\"woman\")\n",
    "print(model.wv.most_similar(\"woman\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most similar to doctor\n",
      "[('adric', 0.568127453327179), ('dentist', 0.5638059377670288), ('nardole', 0.5589247941970825), ('castrovalva', 0.5508528351783752), ('psychiatrist', 0.5506625175476074), ('logopolis', 0.5321011543273926), ('doctors', 0.5305780172348022), ('nurse', 0.529153048992157), ('earthshock', 0.5259256958961487), ('surgeon', 0.525367796421051)]\n"
     ]
    }
   ],
   "source": [
    "print(\"Most similar to\",\"doctor\")\n",
    "print(model.wv.most_similar(\"doctor\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most similar to doctor\n",
      "[('adric', 0.568127453327179), ('dentist', 0.5638059377670288), ('nardole', 0.5589247941970825), ('castrovalva', 0.5508528351783752), ('psychiatrist', 0.5506625175476074), ('logopolis', 0.5321011543273926), ('doctors', 0.5305780172348022), ('nurse', 0.529153048992157), ('earthshock', 0.5259256958961487), ('surgeon', 0.525367796421051)]\n"
     ]
    }
   ],
   "source": [
    "print(\"Most similar to\",\"doctor\")\n",
    "print(model.wv.most_similar(\"doctor\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving some ram by using the KeyedVectors instance\n",
    "wv = model.wv\n",
    "#del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most similar to woman\n",
      "[('girl', 0.7156134247779846), ('man', 0.7035340070724487), ('person', 0.627473771572113), ('prostitute', 0.5917390584945679), ('divorcee', 0.5554578900337219), ('divorcée', 0.5542126893997192), ('policewoman', 0.5420450568199158), ('seductress', 0.5387763381004333), ('housewife', 0.535172164440155), ('frenchwoman', 0.5283711552619934)]\n",
      "\n",
      "Most similar to man\n",
      "[('woman', 0.7035340070724487), ('boy', 0.6310229301452637), ('girl', 0.6180729269981384), ('person', 0.5593484044075012), ('stranger', 0.4969504475593567), ('thug', 0.4957771301269531), ('men', 0.4789658188819885), ('swordsman', 0.4773577153682709), ('policeman', 0.47399353981018066), ('soldier', 0.472536563873291)]\n",
      "\n",
      "Most similar to doctor\n",
      "[('adric', 0.568127453327179), ('dentist', 0.5638059377670288), ('nardole', 0.5589247941970825), ('castrovalva', 0.5508528351783752), ('psychiatrist', 0.5506625175476074), ('logopolis', 0.5321011543273926), ('doctors', 0.5305780172348022), ('nurse', 0.529153048992157), ('earthshock', 0.5259256958961487), ('surgeon', 0.525367796421051)]\n",
      "\n",
      "Most similar to doctor cosmul\n",
      "[('adric', 0.784062922000885), ('dentist', 0.7819021940231323), ('nardole', 0.779461681842804), ('castrovalva', 0.7754256725311279), ('psychiatrist', 0.7753305435180664), ('logopolis', 0.766049861907959), ('doctors', 0.7652882933616638), ('nurse', 0.7645758390426636), ('earthshock', 0.7629621028900146), ('surgeon', 0.7626831531524658)]\n"
     ]
    }
   ],
   "source": [
    "# Testing similarity with KeyedVectors\n",
    "print(\"Most similar to\",\"woman\")\n",
    "print(wv.most_similar(\"woman\"))\n",
    "print(\"\\nMost similar to\",\"man\")\n",
    "print(wv.most_similar(\"man\"))\n",
    "print(\"\\nMost similar to\",\"doctor\")\n",
    "print(wv.most_similar(\"doctor\"))\n",
    "print(\"\\nMost similar to\",\"doctor\",\"cosmul\")\n",
    "print(wv.most_similar_cosmul(positive=[\"doctor\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most similar to woman\n",
      "[('girl', 0.7156134247779846), ('man', 0.7035340070724487), ('person', 0.627473771572113), ('prostitute', 0.5917390584945679), ('divorcee', 0.5554578900337219), ('divorcée', 0.5542126893997192), ('policewoman', 0.5420450568199158), ('seductress', 0.5387763381004333), ('housewife', 0.535172164440155), ('frenchwoman', 0.5283711552619934)]\n",
      "\n",
      "Most similar to man\n",
      "[('woman', 0.7035340070724487), ('boy', 0.6310229301452637), ('girl', 0.6180729269981384), ('person', 0.5593484044075012), ('stranger', 0.4969504475593567), ('thug', 0.4957771301269531), ('men', 0.4789658188819885), ('swordsman', 0.4773577153682709), ('policeman', 0.47399353981018066), ('soldier', 0.472536563873291)]\n",
      "\n",
      "Most similar to doctor\n",
      "[('adric', 0.568127453327179), ('dentist', 0.5638059377670288), ('nardole', 0.5589247941970825), ('castrovalva', 0.5508528351783752), ('psychiatrist', 0.5506625175476074), ('logopolis', 0.5321011543273926), ('doctors', 0.5305780172348022), ('nurse', 0.529153048992157), ('earthshock', 0.5259256958961487), ('surgeon', 0.525367796421051)]\n",
      "\n",
      "Most similar to doctor cosmul\n",
      "[('adric', 0.784062922000885), ('dentist', 0.7819021940231323), ('nardole', 0.779461681842804), ('castrovalva', 0.7754256725311279), ('psychiatrist', 0.7753305435180664), ('logopolis', 0.766049861907959), ('doctors', 0.7652882933616638), ('nurse', 0.7645758390426636), ('earthshock', 0.7629621028900146), ('surgeon', 0.7626831531524658)]\n"
     ]
    }
   ],
   "source": [
    "# Testing similarity with KeyedVectors\n",
    "print(\"Most similar to\",\"woman\")\n",
    "print(wv.most_similar(\"woman\"))\n",
    "print(\"\\nMost similar to\",\"man\")\n",
    "print(wv.most_similar(\"man\"))\n",
    "print(\"\\nMost similar to\",\"doctor\")\n",
    "print(wv.most_similar(\"doctor\"))\n",
    "print(\"\\nMost similar to\",\"doctor\",\"cosmul\")\n",
    "print(wv.most_similar_cosmul(positive=[\"doctor\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "similarity of doctor + woman - man\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('nurse', 0.6044224500656128),\n",
       " ('midwife', 0.5872353911399841),\n",
       " ('gynecologist', 0.5799287557601929),\n",
       " ('physician', 0.5611956119537354),\n",
       " ('psychiatrist', 0.5463466644287109),\n",
       " ('pediatrician', 0.54508376121521),\n",
       " ('gynaecologist', 0.5450509786605835),\n",
       " ('obstetrician', 0.5407373905181885),\n",
       " ('dentist', 0.5338024497032166),\n",
       " ('pharmacist', 0.5186790227890015)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"similarity of doctor + woman - man\")\n",
    "wv.most_similar(positive=[\"doctor\",\"woman\"], negative=[\"man\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "similarity of doctor + woman - man\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('nurse', 0.6044224500656128),\n",
       " ('midwife', 0.5872353911399841),\n",
       " ('gynecologist', 0.5799287557601929),\n",
       " ('physician', 0.5611956119537354),\n",
       " ('psychiatrist', 0.5463466644287109),\n",
       " ('pediatrician', 0.54508376121521),\n",
       " ('gynaecologist', 0.5450509786605835),\n",
       " ('obstetrician', 0.5407373905181885),\n",
       " ('dentist', 0.5338024497032166),\n",
       " ('pharmacist', 0.5186790227890015)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"similarity of doctor + woman - man\")\n",
    "wv.most_similar(positive=[\"doctor\",\"woman\"], negative=[\"man\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cosmul of doctor + woman - man\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('nurse', 0.9101355671882629),\n",
       " ('midwife', 0.9078396558761597),\n",
       " ('gynecologist', 0.901469886302948),\n",
       " ('physician', 0.8901388645172119),\n",
       " ('pediatrician', 0.8833072185516357),\n",
       " ('gynaecologist', 0.8768758773803711),\n",
       " ('obstetrician', 0.8726370930671692),\n",
       " ('psychiatrist', 0.8607419729232788),\n",
       " ('paediatrician', 0.8482840061187744),\n",
       " ('dentist', 0.8474707007408142)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get cosmul of logic\n",
    "print(\"cosmul of doctor + woman - man\")\n",
    "wv.most_similar_cosmul(positive=[\"doctor\",\"woman\"], negative=[\"man\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cosmul of doctor + woman - man\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('nurse', 0.9101355671882629),\n",
       " ('midwife', 0.9078396558761597),\n",
       " ('gynecologist', 0.901469886302948),\n",
       " ('physician', 0.8901388645172119),\n",
       " ('pediatrician', 0.8833072185516357),\n",
       " ('gynaecologist', 0.8768758773803711),\n",
       " ('obstetrician', 0.8726370930671692),\n",
       " ('psychiatrist', 0.8607419729232788),\n",
       " ('paediatrician', 0.8482840061187744),\n",
       " ('dentist', 0.8474707007408142)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get cosmul of logic\n",
    "print(\"cosmul of doctor + woman - man\")\n",
    "wv.most_similar_cosmul(positive=[\"doctor\",\"woman\"], negative=[\"man\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get item dog\n",
      "vec_dog (300,) [-2.6634293   2.3062525   0.19561668  0.7163729  -0.52825516 -0.0074518\n",
      "  1.9209532  -0.3408677  -1.0190932   0.07459767]\n"
     ]
    }
   ],
   "source": [
    "# Ways to retrive word vector\n",
    "print(\"Get item dog\")\n",
    "vec_dog = wv.__getitem__(\"dog\")\n",
    "vec_dog = wv.get_vector(\"dog\")\n",
    "vec_dog = wv.word_vec(\"dog\")\n",
    "print(\"vec_dog\", vec_dog.shape, vec_dog[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similar by vector to dog vector at top 10\n",
      "[('dog', 1.0), ('dogs', 0.7544571161270142), ('cat', 0.7354434132575989), ('puppy', 0.6880402565002441), ('dachshund', 0.6825794577598572), ('rabbit', 0.6537305116653442), ('rottweiler', 0.6467593908309937), ('poodle', 0.6438148021697998), ('pig', 0.6335182189941406), ('hound', 0.6029298305511475)]\n",
      "Most similar to dog vector\n",
      "[('dog', 1.0), ('dogs', 0.7544571161270142), ('cat', 0.7354434132575989), ('puppy', 0.6880402565002441), ('dachshund', 0.6825794577598572), ('rabbit', 0.6537305116653442), ('rottweiler', 0.6467593908309937), ('poodle', 0.6438148021697998), ('pig', 0.6335182189941406), ('hound', 0.6029298305511475)]\n",
      "Similar to cat vector\n",
      "[('cat', 1.0), ('dog', 0.7354434728622437), ('rabbit', 0.6862228512763977), ('kitten', 0.6151206493377686), ('poodle', 0.6113007068634033), ('mouse', 0.6038779616355896), ('monkey', 0.6029018759727478), ('meow', 0.5950917601585388), ('hairball', 0.5898336172103882), ('cats', 0.5890979766845703)]\n"
     ]
    }
   ],
   "source": [
    "# Get similar words to vector\n",
    "print(\"Similar by vector to dog vector at top 10\")\n",
    "print(wv.similar_by_vector(vector=vec_dog, topn=10, restrict_vocab=None))\n",
    "print(\"Most similar to dog vector\")\n",
    "print(wv.most_similar(positive=[vec_dog]))\n",
    "print(\"Similar to cat vector\")\n",
    "vec_cat = wv.word_vec(\"cat\")\n",
    "print(wv.most_similar(positive=[vec_cat]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "closer to dog than cat\n",
      "['dogs']\n",
      "\n",
      "closer to cat than dog\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "# closer to __ than __\n",
    "print(\"closer to dog than cat\")\n",
    "print(wv.words_closer_than(\"dog\", \"cat\"))\n",
    "print(\"\\ncloser to cat than dog\")\n",
    "print(wv.words_closer_than(\"cat\", \"dog\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vec_king_norm: (300,) [ 0.01541833 -0.01279872 -0.01601281  0.02326567  0.08323052  0.02704921\n",
      "  0.04290665  0.06306878  0.1487852   0.03694476]\n",
      "vec_king_unnorm: (300,) [ 0.4366548  -0.36246604 -0.45349073  0.6588954   2.3571293   0.766047\n",
      "  1.2151375   1.786139    4.2136703   1.0462939 ]\n"
     ]
    }
   ],
   "source": [
    "# Normalized Vector\n",
    "vec_king_norm = wv.word_vec(\"king\", use_norm=True)\n",
    "print(\"vec_king_norm:\",vec_king_norm.shape, vec_king_norm[:10])\n",
    "# Not normalized vectore\n",
    "vec_king_unnorm = wv.word_vec(\"king\", use_norm=False)\n",
    "print(\"vec_king_unnorm:\",vec_king_norm.shape, vec_king_unnorm[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('utilized', 0.3044779598712921),\n",
       " ('focused', 0.278587281703949),\n",
       " ('categorized', 0.275567889213562),\n",
       " ('saenchuanglek', 0.2754442095756531),\n",
       " ('braese', 0.2734081447124481),\n",
       " ('neshwille', 0.27287906408309937),\n",
       " ('knocknaskeharoe', 0.26975083351135254),\n",
       " ('structured', 0.2687339186668396),\n",
       " ('contributing', 0.265920490026474),\n",
       " ('individualistic', 0.2639663815498352)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wv.most_similar(positive=[vec_king_norm], negative=[vec_king_unnorm])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "similar to random vector\n",
      "[('vicarios', 0.27943286299705505), ('ビョウbyō', 0.2677918076515198), ('pyrophore', 0.2634037137031555), ('rarily', 0.26206454634666443), ('mosquital', 0.26157671213150024), ('polymedicine', 0.2607215344905853), ('uaauk', 0.2604387700557709), ('ezrianne', 0.25792568922042847), ('adnahome', 0.2576918601989746), ('muihki', 0.25721096992492676)]\n",
      "\n",
      " similar to nomalized random vector\n",
      "[('vicarios', 0.27943286299705505), ('ビョウbyō', 0.2677918076515198), ('pyrophore', 0.2634037137031555), ('rarily', 0.26206454634666443), ('mosquital', 0.26157671213150024), ('polymedicine', 0.2607215344905853), ('uaauk', 0.2604387700557709), ('ezrianne', 0.25792568922042847), ('adnahome', 0.2576918601989746), ('muihki', 0.25721096992492676)]\n"
     ]
    }
   ],
   "source": [
    "# Generate random vector\n",
    "import numpy as np\n",
    "vec_random = np.random.rand(300,)\n",
    "vec_random_norm = vec_random / vec_random.max(axis=0)\n",
    "print(\"similar to random vector\")\n",
    "print(wv.most_similar(positive=[vec_random]))\n",
    "print(\"\\n similar to nomalized random vector\")\n",
    "print(wv.most_similar(positive=[vec_random_norm]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "similarity from a normalized random vector to normalized vector of king\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('vicarios', 0.28092366456985474),\n",
       " ('rarily', 0.2663201093673706),\n",
       " ('pyrophore', 0.26312553882598877),\n",
       " ('polymedicine', 0.26185768842697144),\n",
       " ('muihki', 0.2599378228187561),\n",
       " ('uaauk', 0.25813591480255127),\n",
       " ('krath', 0.2575136423110962),\n",
       " ('ビョウbyō', 0.25641798973083496),\n",
       " ('mosquital', 0.2561648488044739),\n",
       " ('张蓓蓓', 0.25569337606430054)]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get similarity from a random vector and normilized king vector\n",
    "print(\"similarity from a normalized random vector to normalized vector of king\")\n",
    "wv.most_similar(positive=[vec_random_norm,vec_king_norm])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "similarity from a random vector to unormalized vector of king\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('king', 0.9413427114486694),\n",
       " ('queen', 0.6534480452537537),\n",
       " ('prince', 0.6449348330497742),\n",
       " ('kings', 0.5767666697502136),\n",
       " ('emperor', 0.5365402102470398),\n",
       " ('monarch', 0.528211236000061),\n",
       " ('throne', 0.4935380220413208),\n",
       " ('crown', 0.49160435795783997),\n",
       " ('aethelred', 0.4883429706096649),\n",
       " ('princess', 0.48811477422714233)]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get similarity from a random vector and unormalized king vector\n",
    "print(\"similarity from a random vector to unormalized vector of king\")\n",
    "wv.most_similar(positive=[vec_random,vec_king_unnorm])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cosine similarity from a random vector to unormalized vector of king\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-0.02642212])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get cosine similarities from a vector to an array of vectors\n",
    "print(\"cosine similarity from a random vector to unormalized vector of king\")\n",
    "wv.cosine_similarities(vec_random, [vec_king_unnorm])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tests analogies based on a text file\n",
    "analogy_scores = wv.accuracy('datasets/questions-words.txt')\n",
    "#print(analogy_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distance between dog and cat\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.26455658819142336"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The the distance of two words\n",
    "print(\"distance between dog and cat\")\n",
    "wv.distance(\"dog\",\"cat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distance from dog to king and cat\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.8180392 , 0.26455647], dtype=float32)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the distance of a word for the list of word\n",
    "print(\"distance from dog to king and cat\")\n",
    "wv.distances(\"dog\",[\"king\",\"cat\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate pairs of words\n",
    "#wv.evaluate_word_pairs(\"datasets/SimLex-999.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get sentence similarities\n",
    "\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim.utils import simple_preprocess    \n",
    "\n",
    "def tokemmized(sentence, vocabulary):\n",
    "    tokens = [lem(word) for word in simple_preprocess(sentence)]\n",
    "    return [word for word in tokens if word in vocabulary]   \n",
    "\n",
    "def compute_sentence_similarity(sentence_1, sentence_2, model_wv):\n",
    "    vocabulary = set(model_wv.index2word)\n",
    "    tokens_1 = tokemmized(sentence_1, vocabulary)\n",
    "    tokens_2 = tokemmized(sentence_2, vocabulary)\n",
    "    del vocabulary\n",
    "    print(tokens_1, tokens_2)\n",
    "    return model_wv.n_similarity(tokens_1, tokens_2)\n",
    "\n",
    "similarity = compute_sentence_similarity('this is a sentence', 'this is also a sentence', wv)\n",
    "print(similarity,\"\\n\")\n",
    "\n",
    "similarity = compute_sentence_similarity('the cat is a mammal', 'the bird is a aves', wv)\n",
    "print(similarity,\"\\n\")\n",
    "\n",
    "similarity = compute_sentence_similarity('the cat is a mammal', 'the dog is a mammal', wv)\n",
    "print(similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "france is to france as berlin is to ?\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('germany', 0.8275506496429443),\n",
       " ('berlin', 0.6908831596374512),\n",
       " ('france', 0.6784806251525879),\n",
       " ('poland', 0.633112907409668),\n",
       " ('german', 0.588524341583252),\n",
       " ('russia', 0.5857172012329102),\n",
       " ('italy', 0.5818371772766113),\n",
       " ('europe', 0.5750494003295898),\n",
       " ('austria', 0.5719729065895081),\n",
       " ('netherlands', 0.5547516345977783)]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Analogy with not normalized vectors\n",
    "print(\"france is to paris as berlin is to ?\")\n",
    "wv.most_similar([wv['france'] - wv['paris'] + wv['berlin']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "france is to paris as berlin is to ?\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('germany', 0.820073664188385),\n",
       " ('berlin', 0.6869513988494873),\n",
       " ('france', 0.6479591727256775),\n",
       " ('poland', 0.6227378845214844),\n",
       " ('german', 0.5865136384963989),\n",
       " ('russia', 0.5743523836135864),\n",
       " ('italy', 0.5623424053192139),\n",
       " ('austria', 0.5614084005355835),\n",
       " ('europe', 0.5605403184890747),\n",
       " ('netherlands', 0.5417272448539734)]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Analogy with normalized Vector\n",
    "vec_france_norm = wv.word_vec('france', use_norm=True)\n",
    "vec_paris_norm = wv.word_vec('paris', use_norm=True)\n",
    "vec_berlin_norm = wv.word_vec('berlin', use_norm=True)\n",
    "vec_germany_norm = wv.word_vec('germany', use_norm=True)\n",
    "vec_country_norm = wv.word_vec('country', use_norm=True)\n",
    "print(\"france is to paris as berlin is to ?\")\n",
    "wv.most_similar([vec_france_norm - vec_paris_norm + vec_berlin_norm])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cosine_similarities of france and paris\n",
      "[0.6420748]\n",
      "cosine_similarities of france and berlin\n",
      "[0.36795506]\n",
      "cosine_similarities of france and country\n",
      "[0.32212678]\n"
     ]
    }
   ],
   "source": [
    "# Cosine Similarities\n",
    "print(\"cosine_similarities of france and paris\")\n",
    "print(wv.cosine_similarities(vec_france_norm, [vec_paris_norm]))\n",
    "print(\"cosine_similarities of france and berlin\")\n",
    "print(wv.cosine_similarities(vec_france_norm, [vec_berlin_norm]))\n",
    "print(\"cosine_similarities of france and country\")\n",
    "print(wv.cosine_similarities(vec_france_norm, [vec_country_norm]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Man is to Woman what King is to ?\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('king', 0.80283522605896),\n",
       " ('kings', 0.5250919461250305),\n",
       " ('prince', 0.5248726606369019),\n",
       " ('iii', 0.45816951990127563),\n",
       " ('lord', 0.45348936319351196),\n",
       " ('iv', 0.45300135016441345),\n",
       " ('vi', 0.44630226492881775),\n",
       " ('conqueror', 0.4445120692253113),\n",
       " ('ii', 0.41359907388687134),\n",
       " ('emperor', 0.4134453535079956)]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Analogy\n",
    "print(\"Man is to Woman what King is to ?\")\n",
    "wv.most_similar([wv['man'] - wv['woman'] + wv['king']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "paris is to france as berlin is to ?\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('berlin', 0.8213962912559509),\n",
       " ('munich', 0.6599953770637512),\n",
       " ('paris', 0.6203441619873047),\n",
       " ('bonn', 0.6191271543502808),\n",
       " ('vienna', 0.6118754744529724),\n",
       " ('dresden', 0.605978786945343),\n",
       " ('leipzig', 0.6040723323822021),\n",
       " ('düsseldorf', 0.5992366075515747),\n",
       " ('charlottenburg', 0.5932153463363647),\n",
       " ('hamburg', 0.5931907892227173)]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Analogy\n",
    "print(\"paris is to france as berlin is to ?\")\n",
    "wv.most_similar([wv['paris'] - wv['france'] + wv['berlin']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat is to mammal as sparrow is to ?\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('cat', 0.6686296463012695),\n",
       " ('sparrow', 0.661421537399292),\n",
       " ('kitty', 0.5254508852958679),\n",
       " ('ruby', 0.4817608892917633),\n",
       " ('kitten', 0.46180397272109985),\n",
       " ('rabbit', 0.4520624876022339),\n",
       " ('aka', 0.45059120655059814),\n",
       " ('dog', 0.44592469930648804),\n",
       " ('angel', 0.44519680738449097),\n",
       " ('granny', 0.4402121305465698)]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Analogy\n",
    "print(\"cat is to mammal as sparrow is to ?\")\n",
    "wv.most_similar([wv['cat'] - wv['mammal'] + wv['sparrow']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grass is to green as sky is to ?\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('grass', 0.7242218255996704),\n",
       " ('sky', 0.5100921392440796),\n",
       " ('tussocks', 0.46009260416030884),\n",
       " ('grasses', 0.4372618794441223),\n",
       " ('bermudagrass', 0.42268460988998413),\n",
       " ('weeds', 0.4198673367500305),\n",
       " ('marram', 0.4184962511062622),\n",
       " ('tussac', 0.4171423316001892),\n",
       " ('bentgrass', 0.4109356999397278),\n",
       " ('skies', 0.4039731025695801)]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Analogy\n",
    "print(\"grass is to green as sky is to ?\")\n",
    "wv.most_similar([wv['sky'] - wv['blue'] + wv['grass']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "athens is to greece as baghdad is to ?\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('iraq', 0.7558031678199768),\n",
       " ('baghdad', 0.6576923131942749),\n",
       " ('afghanistan', 0.6100637316703796),\n",
       " ('iraqi', 0.6068007946014404),\n",
       " ('tikrit', 0.5783915519714355),\n",
       " ('mosul', 0.5627672672271729),\n",
       " ('fallujah', 0.5387886762619019),\n",
       " ('damascus', 0.5282827615737915),\n",
       " ('kabul', 0.5265875458717346),\n",
       " ('kuwait', 0.5214947462081909)]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Analogy\n",
    "print(\"athens is to greece as baghdad is to ?\")\n",
    "wv.most_similar([wv['athens'] - wv['greece'] + wv['iraq']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('city', 0.8364958763122559),\n",
       " ('capital', 0.8285309672355652),\n",
       " ('town', 0.5625525712966919),\n",
       " ('cities', 0.5351611971855164),\n",
       " ('downtown', 0.5260708928108215),\n",
       " ('municipal', 0.5095252990722656),\n",
       " ('territory', 0.4946771264076233),\n",
       " ('district', 0.48831993341445923),\n",
       " ('metropolis', 0.4836964011192322),\n",
       " ('region', 0.4836798906326294)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wv.most_similar([wv[\"capital\"]+wv[\"city\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-04-17 18:52:01,516 : INFO : precomputing L2-norms of word weight vectors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "athens is to greece as baghdad is to ?\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('science', 0.7434406280517578),\n",
       " ('capital', 0.6892884969711304),\n",
       " ('sciences', 0.6157187819480896),\n",
       " ('biotechnology', 0.5573773384094238),\n",
       " ('technology', 0.5531710386276245),\n",
       " ('economics', 0.5489161610603333),\n",
       " ('humanities', 0.5242317318916321),\n",
       " ('informatics', 0.5220810770988464),\n",
       " ('institute', 0.5044348239898682),\n",
       " ('university', 0.49241507053375244)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Analogy\n",
    "print(\"capital + science\")\n",
    "wv.most_similar([wv['capital'] + wv['science']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.07976063, 0.03727365, 0.31391722], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wv.cosine_similarities(wv[\"education\"], [wv[\"natality\"],wv[\"salubrity\"],wv[\"economy\"]]\n",
    "\n",
    "#wv.distance(\"education\",\"natality\")\n",
    "\n",
    "# education, natality, salubrity, economy\n",
    "\n",
    "#wv.most_similar_cosmul(positive=[\"doctor\",\"woman\"], negative=[\"man\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
