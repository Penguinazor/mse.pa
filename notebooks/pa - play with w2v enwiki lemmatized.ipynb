{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn on Auto-Complete\n",
    "%config IPCompleter.greedy=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start logging process at root level\n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "logging.root.setLevel(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model and dictionary\n",
    "#model_id_current = 99999\n",
    "#model_path_current = \"models/enwiki-full-dict-\"+str(model_id_current)+\".model\"\n",
    "#model_path_99999 = \"models/enwiki-20190319-lemmatized-99999.model\"\n",
    "model_path_current =\"models/enwiki-20190409-lemmatized.model\"\n",
    "\n",
    "dictionary_full_wikien_lem_path = \"dictionaries/enwiki-20190409-dict-lemmatized.txt.bz2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-04-23 12:51:02,012 : INFO : 'pattern' package found; tag filters are available for English\n",
      "2019-04-23 12:51:02,021 : INFO : loading Word2Vec object from models/enwiki-20190409-lemmatized.model\n",
      "2019-04-23 12:52:19,106 : INFO : loading wv recursively from models/enwiki-20190409-lemmatized.model.wv.* with mmap=r\n",
      "2019-04-23 12:52:19,109 : INFO : loading vectors from models/enwiki-20190409-lemmatized.model.wv.vectors.npy with mmap=r\n",
      "2019-04-23 12:52:19,130 : INFO : setting ignored attribute vectors_norm to None\n",
      "2019-04-23 12:52:19,135 : INFO : loading vocabulary recursively from models/enwiki-20190409-lemmatized.model.vocabulary.* with mmap=r\n",
      "2019-04-23 12:52:19,137 : INFO : loading trainables recursively from models/enwiki-20190409-lemmatized.model.trainables.* with mmap=r\n",
      "2019-04-23 12:52:19,139 : INFO : loading syn1neg from models/enwiki-20190409-lemmatized.model.trainables.syn1neg.npy with mmap=r\n",
      "2019-04-23 12:52:19,143 : INFO : loading vectors_lockf from models/enwiki-20190409-lemmatized.model.trainables.vectors_lockf.npy with mmap=r\n",
      "2019-04-23 12:52:19,146 : INFO : setting ignored attribute cum_table to None\n",
      "2019-04-23 12:52:19,147 : INFO : loaded models/enwiki-20190409-lemmatized.model\n"
     ]
    }
   ],
   "source": [
    "# Load word2vec unlemmatized model\n",
    "from gensim.models import Word2Vec\n",
    "model = Word2Vec.load(model_path_current, mmap='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dog/NN\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Custom lemmatizer function to play with word\n",
    "from gensim.utils import lemmatize\n",
    "#vocabulary = set(wv.index2word)\n",
    "def lem(word):\n",
    "    try:\n",
    "        return lemmatize(word)[0].decode(\"utf-8\")\n",
    "    except:\n",
    "        pass\n",
    "        \n",
    "print(lem(\"dog\"))\n",
    "print(lem(\"that\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most similar to woman\n",
      "[('man/NN', 0.6361385583877563), ('individual/NN', 0.5763572454452515), ('person/NN', 0.5568535327911377), ('girl/NN', 0.5561789274215698), ('female/JJ', 0.54877769947052), ('female/NN', 0.5409574508666992), ('lesbian/NN', 0.5204395055770874), ('gender/NN', 0.5188673734664917), ('child/NN', 0.4933265447616577), ('feminist/NN', 0.4769814610481262)]\n"
     ]
    }
   ],
   "source": [
    "# Testing similarity\n",
    "print(\"Most similar to\",\"woman\")\n",
    "print(model.wv.most_similar(lem(\"woman\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most similar to doctor\n",
      "[('dentist/NN', 0.5610849261283875), ('nardole/NN', 0.5584279894828796), ('nurse/NN', 0.5565731525421143), ('physician/NN', 0.5523163080215454), ('dolittle/RB', 0.5519494414329529), ('psychiatrist/NN', 0.5512733459472656), ('veterinarian/NN', 0.523552417755127), ('naakudu/RB', 0.5198249816894531), ('zhivago/VB', 0.5178859233856201), ('senocak/RB', 0.5164788961410522)]\n"
     ]
    }
   ],
   "source": [
    "print(\"Most similar to\",\"doctor\")\n",
    "print(model.wv.most_similar(lem(\"doctor\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving some ram by using the KeyedVectors instance\n",
    "wv = model.wv\n",
    "#del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most similar to woman\n",
      "[('man/NN', 0.6361385583877563), ('individual/NN', 0.5763572454452515), ('person/NN', 0.5568535327911377), ('girl/NN', 0.5561789274215698), ('female/JJ', 0.54877769947052), ('female/NN', 0.5409574508666992), ('lesbian/NN', 0.5204395055770874), ('gender/NN', 0.5188673734664917), ('child/NN', 0.4933265447616577), ('feminist/NN', 0.4769814610481262)]\n",
      "\n",
      "Most similar to man\n",
      "[('woman/NN', 0.6361386179924011), ('boy/NN', 0.5653619170188904), ('person/NN', 0.5352815389633179), ('girl/NN', 0.5206164121627808), ('individual/NN', 0.49065500497817993), ('soldier/NN', 0.4820939302444458), ('spiderlongclose/VB', 0.46156802773475647), ('someone/NN', 0.4581664502620697), ('mcglurk/NN', 0.4518073499202728), ('one/NN', 0.4458999037742615)]\n",
      "\n",
      "Most similar to doctor\n",
      "[('dentist/NN', 0.5610849261283875), ('nardole/NN', 0.5584279894828796), ('nurse/NN', 0.5565731525421143), ('physician/NN', 0.5523163080215454), ('dolittle/RB', 0.5519494414329529), ('psychiatrist/NN', 0.5512733459472656), ('veterinarian/NN', 0.523552417755127), ('naakudu/RB', 0.5198249816894531), ('zhivago/VB', 0.5178859233856201), ('senocak/RB', 0.5164788961410522)]\n",
      "\n",
      "Most similar to doctor cosmul\n",
      "[('dentist/NN', 0.7805417776107788), ('nardole/NN', 0.7792133092880249), ('nurse/NN', 0.7782858610153198), ('physician/NN', 0.7761574387550354), ('dolittle/RB', 0.7759740352630615), ('psychiatrist/NN', 0.7756359577178955), ('veterinarian/NN', 0.7617754936218262), ('naakudu/RB', 0.7599117755889893), ('zhivago/VB', 0.7589422464370728), ('senocak/RB', 0.7582387328147888)]\n"
     ]
    }
   ],
   "source": [
    "# Testing similarity with KeyedVectors\n",
    "print(\"Most similar to\",\"woman\")\n",
    "print(wv.most_similar(lem(\"woman\")))\n",
    "print(\"\\nMost similar to\",\"man\")\n",
    "print(wv.most_similar(lem(\"man\")))\n",
    "print(\"\\nMost similar to\",\"doctor\")\n",
    "print(wv.most_similar(lem(\"doctor\")))\n",
    "print(\"\\nMost similar to\",\"doctor\",\"cosmul\")\n",
    "print(wv.most_similar_cosmul(positive=[lem(\"doctor\")]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "similarity of doctor + woman - man\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('midwife/NN', 0.6090542078018188),\n",
       " ('nurse/NN', 0.5804013609886169),\n",
       " ('physician/NN', 0.5530248880386353),\n",
       " ('gynaecologist/NN', 0.5421075820922852),\n",
       " ('obstetrician/NN', 0.5344318151473999),\n",
       " ('medical/JJ', 0.5299170017242432),\n",
       " ('midwive/VB', 0.5122523903846741),\n",
       " ('anaesthetist/NN', 0.502942681312561),\n",
       " ('nursing/NN', 0.5021981000900269),\n",
       " ('naakudu/RB', 0.5021182298660278)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"similarity of doctor + woman - man\")\n",
    "wv.most_similar(positive=[lem(\"doctor\"),lem(\"woman\")], negative=[lem(\"man\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cosmul of doctor + woman - man\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('midwife/NN', 0.9296931624412537),\n",
       " ('nurse/NN', 0.8866435289382935),\n",
       " ('gynaecologist/NN', 0.8841131329536438),\n",
       " ('midwive/VB', 0.8803321123123169),\n",
       " ('obstetrician/NN', 0.8797454237937927),\n",
       " ('physician/NN', 0.8750578165054321),\n",
       " ('medical/JJ', 0.8747599124908447),\n",
       " ('midwifery/NN', 0.874646008014679),\n",
       " ('nursing/NN', 0.867769181728363),\n",
       " ('naturopathic/JJ', 0.8633977770805359)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get cosmul of logic\n",
    "print(\"cosmul of doctor + woman - man\")\n",
    "wv.most_similar_cosmul(positive=[lem(\"doctor\"),lem(\"woman\")], negative=[lem(\"man\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get item dog\n",
      "vec_dog (300,) [-0.13817333 -1.8090004  -0.45946687 -2.2184215   1.4197063   0.19401991\n",
      " -0.4230487  -2.7905297  -3.1192808   0.02542385]\n"
     ]
    }
   ],
   "source": [
    "# Ways to retrive word vector\n",
    "print(\"Get item dog\")\n",
    "vec_dog = wv.__getitem__(\"dog/NN\")\n",
    "vec_dog = wv.get_vector(\"dog/NN\")\n",
    "vec_dog = wv.word_vec(\"dog/NN\")\n",
    "print(\"vec_dog\", vec_dog.shape, vec_dog[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similar by vector to dog vector at top 10\n",
      "[('dog/NN', 1.0000001192092896), ('cat/NN', 0.7325705289840698), ('puppy/NN', 0.7017959356307983), ('dogs/NN', 0.6933757066726685), ('dachshund/NN', 0.6861976981163025), ('poodle/NN', 0.6616296768188477), ('rottweiler/JJ', 0.6588126420974731), ('hound/NN', 0.6473891139030457), ('pet/NN', 0.6361759901046753), ('pekingese/JJ', 0.6296164989471436)]\n",
      "Most similar to dog vector\n",
      "[('dog/NN', 1.0000001192092896), ('cat/NN', 0.7325705289840698), ('puppy/NN', 0.7017959356307983), ('dogs/NN', 0.6933757066726685), ('dachshund/NN', 0.6861976981163025), ('poodle/NN', 0.6616296768188477), ('rottweiler/JJ', 0.6588126420974731), ('hound/NN', 0.6473891139030457), ('pet/NN', 0.6361759901046753), ('pekingese/JJ', 0.6296164989471436)]\n",
      "Similar to cat vector\n",
      "[('cat/NN', 1.0), ('dog/NN', 0.7325705885887146), ('meow/VB', 0.6924092769622803), ('kitten/NN', 0.6764312982559204), ('catjuan/JJ', 0.639890193939209), ('rabbit/NN', 0.6368660926818848), ('meow/NN', 0.635756254196167), ('fraidy/JJ', 0.6297948360443115), ('poodle/NN', 0.6230608224868774), ('pet/NN', 0.6119345426559448)]\n"
     ]
    }
   ],
   "source": [
    "# Get similar words to vector\n",
    "print(\"Similar by vector to dog vector at top 10\")\n",
    "print(wv.similar_by_vector(vector=vec_dog, topn=10, restrict_vocab=None))\n",
    "print(\"Most similar to dog vector\")\n",
    "print(wv.most_similar(positive=[vec_dog]))\n",
    "print(\"Similar to cat vector\")\n",
    "vec_cat = wv.word_vec(\"cat/NN\")\n",
    "print(wv.most_similar(positive=[vec_cat]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "closer to dog than cat\n",
      "[]\n",
      "\n",
      "closer to cat than dog\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "# closer to __ than __\n",
    "print(\"closer to dog than cat\")\n",
    "print(wv.words_closer_than(\"dog/NN\", \"cat/NN\"))\n",
    "print(\"\\ncloser to cat than dog\")\n",
    "print(wv.words_closer_than(\"cat/NN\", \"dog/NN\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vec_king_norm: (300,) [ 0.02464886  0.09053605  0.00468578 -0.01604057  0.0808396   0.10550086\n",
      "  0.01262516 -0.0464116  -0.06513052 -0.08347644]\n",
      "vec_king_unnorm: (300,) [ 0.6677862   2.4528      0.12694712 -0.43457067  2.190104    2.8582263\n",
      "  0.34204054 -1.2573817  -1.764514   -2.2615411 ]\n"
     ]
    }
   ],
   "source": [
    "# Normalized Vector\n",
    "vec_king_norm = wv.word_vec(\"king/NN\", use_norm=True)\n",
    "print(\"vec_king_norm:\",vec_king_norm.shape, vec_king_norm[:10])\n",
    "# Not normalized vectore\n",
    "vec_king_unnorm = wv.word_vec(\"king/NN\", use_norm=False)\n",
    "print(\"vec_king_unnorm:\",vec_king_norm.shape, vec_king_unnorm[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('пилкохвіст/NN', 0.3219989538192749),\n",
       " ('scheidermantel/NN', 0.3141171336174011),\n",
       " ('pafnutyevich/JJ', 0.3104780912399292),\n",
       " ('samodeyatelnost/NN', 0.3033001720905304),\n",
       " ('黃毓祺/JJ', 0.29464849829673767),\n",
       " ('zakhozha/NN', 0.2945646047592163),\n",
       " ('слободян/NN', 0.29284998774528503),\n",
       " ('joenni/NN', 0.28914523124694824),\n",
       " ('lyubarina/NN', 0.2868795692920685),\n",
       " ('rsheuski/NN', 0.28535693883895874)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wv.most_similar(positive=[vec_king_norm], negative=[vec_king_unnorm])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "similar to random vector\n",
      "[('parigine/VB', 0.28092506527900696), ('nmcue/NN', 0.2804727852344513), ('mozart_kv/NN', 0.2786831855773926), ('tabuur/VB', 0.27440786361694336), ('tanantella/NN', 0.2741648852825165), ('kalfhani/NN', 0.27331894636154175), ('小法廷/VB', 0.27157384157180786), ('molagholi/VB', 0.2650672495365143), ('kriesinger/NN', 0.2646629810333252), ('shōhōtei/NN', 0.26364269852638245)]\n",
      "\n",
      " similar to nomalized random vector\n",
      "[('parigine/VB', 0.28092506527900696), ('nmcue/NN', 0.2804727852344513), ('mozart_kv/NN', 0.2786831855773926), ('tabuur/VB', 0.27440786361694336), ('tanantella/NN', 0.2741648852825165), ('kalfhani/NN', 0.27331894636154175), ('小法廷/VB', 0.27157384157180786), ('molagholi/VB', 0.2650672495365143), ('kriesinger/NN', 0.2646629810333252), ('shōhōtei/NN', 0.26364269852638245)]\n"
     ]
    }
   ],
   "source": [
    "# Generate random vector\n",
    "import numpy as np\n",
    "vec_random = np.random.rand(300,)\n",
    "vec_random_norm = vec_random / vec_random.max(axis=0)\n",
    "print(\"similar to random vector\")\n",
    "print(wv.most_similar(positive=[vec_random]))\n",
    "print(\"\\n similar to nomalized random vector\")\n",
    "print(wv.most_similar(positive=[vec_random_norm]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "similarity from a normalized random vector to normalized vector of king\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('parigine/VB', 0.2886022925376892),\n",
       " ('kalfhani/NN', 0.27668145298957825),\n",
       " ('kriesinger/NN', 0.27662235498428345),\n",
       " ('小法廷/VB', 0.27649563550949097),\n",
       " ('nmcue/NN', 0.27467527985572815),\n",
       " ('regent/NN', 0.27348271012306213),\n",
       " ('mozart_kv/NN', 0.27183622121810913),\n",
       " ('shōhōtei/NN', 0.2708197832107544),\n",
       " ('tabuur/VB', 0.27058061957359314),\n",
       " ('hangedup/JJ', 0.2701559066772461)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get similarity from a random vector and normilized king vector\n",
    "print(\"similarity from a normalized random vector to normalized vector of king\")\n",
    "wv.most_similar(positive=[vec_random_norm,vec_king_norm])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "similarity from a random vector to unormalized vector of king\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('king/NN', 0.9415208697319031),\n",
       " ('prince/NN', 0.6032038927078247),\n",
       " ('queen/NN', 0.5944242477416992),\n",
       " ('monarch/NN', 0.5747672319412231),\n",
       " ('throne/NN', 0.5345853567123413),\n",
       " ('crown/NN', 0.5192743539810181),\n",
       " ('ruler/NN', 0.5041853189468384),\n",
       " ('emperor/NN', 0.48576343059539795),\n",
       " ('coronation/NN', 0.475940078496933),\n",
       " ('lord/NN', 0.47265052795410156)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get similarity from a random vector and unormalized king vector\n",
    "print(\"similarity from a random vector to unormalized vector of king\")\n",
    "wv.most_similar(positive=[vec_random,vec_king_unnorm])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cosine similarity from a random vector to unormalized vector of king\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.10765238])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get cosine similarities from a vector to an array of vectors\n",
    "print(\"cosine similarity from a random vector to unormalized vector of king\")\n",
    "wv.cosine_similarities(vec_random, [vec_king_unnorm])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tests analogies based on a text file\n",
    "analogy_scores = wv.accuracy('datasets/questions-words.txt')\n",
    "#print(analogy_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distance between dog and cat\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.2674294870033782"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The the distance of two words\n",
    "print(\"distance between dog and cat\")\n",
    "wv.distance(\"dog/NN\",\"cat/NN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distance from dog to king and cat\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.81238294, 0.26742947], dtype=float32)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the distance of a word for the list of word\n",
    "print(\"distance from dog to king and cat\")\n",
    "wv.distances(\"dog/NN\",[\"king/NN\",\"cat/NN\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate pairs of words\n",
    "#wv.evaluate_word_pairs(\"datasets/SimLex-999.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['be/VB', 'sentence/NN'] ['be/VB', 'also/RB', 'sentence/NN']\n",
      "0.9267933550381176 \n",
      "\n",
      "['cat/NN', 'be/VB', 'mammal/NN'] ['bird/NN', 'be/VB', 'ave/NN']\n",
      "0.6503839221443558 \n",
      "\n",
      "['cat/NN', 'be/VB', 'mammal/NN'] ['dog/NN', 'be/VB', 'mammal/NN']\n",
      "0.9425444280677167\n"
     ]
    }
   ],
   "source": [
    "# Get sentence similarities\n",
    "\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim.utils import simple_preprocess    \n",
    "\n",
    "def tokemmized(sentence, vocabulary):\n",
    "    tokens = [lem(word) for word in simple_preprocess(sentence)]\n",
    "    return [word for word in tokens if word in vocabulary]   \n",
    "\n",
    "def compute_sentence_similarity(sentence_1, sentence_2, model_wv):\n",
    "    vocabulary = set(model_wv.index2word)\n",
    "    tokens_1 = tokemmized(sentence_1, vocabulary)\n",
    "    tokens_2 = tokemmized(sentence_2, vocabulary)\n",
    "    del vocabulary\n",
    "    print(tokens_1, tokens_2)\n",
    "    return model_wv.n_similarity(tokens_1, tokens_2)\n",
    "\n",
    "similarity = compute_sentence_similarity('this is a sentence', 'this is also a sentence', wv)\n",
    "print(similarity,\"\\n\")\n",
    "\n",
    "similarity = compute_sentence_similarity('the cat is a mammal', 'the bird is a aves', wv)\n",
    "print(similarity,\"\\n\")\n",
    "\n",
    "similarity = compute_sentence_similarity('the cat is a mammal', 'the dog is a mammal', wv)\n",
    "print(similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "france is to paris as berlin is to ?\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('germany/NN', 0.7672240138053894),\n",
       " ('berlin/NN', 0.6933715343475342),\n",
       " ('france/NN', 0.5758201479911804),\n",
       " ('uedem/NN', 0.5712798833847046),\n",
       " ('gdr/NN', 0.5634602308273315),\n",
       " ('osnabrueck/NN', 0.5577783584594727),\n",
       " ('cottbu/NN', 0.5571167469024658),\n",
       " ('najallah/NN', 0.5441399812698364),\n",
       " ('hüttenjazz/NN', 0.539354145526886),\n",
       " ('german/NN', 0.5388710498809814)]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Analogy with not normalized vectors\n",
    "print(\"france is to paris as berlin is to ?\")\n",
    "wv.most_similar([wv['france/NN'] - wv['paris/NN'] + wv['berlin/NN']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "france is to paris as berlin is to ?\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('germany/NN', 0.7600144743919373),\n",
       " ('berlin/NN', 0.6725304126739502),\n",
       " ('uedem/NN', 0.5701783299446106),\n",
       " ('france/NN', 0.5680463910102844),\n",
       " ('gdr/NN', 0.5581510663032532),\n",
       " ('cottbu/NN', 0.5506802797317505),\n",
       " ('osnabrueck/NN', 0.5495263338088989),\n",
       " ('najallah/NN', 0.5433506965637207),\n",
       " ('hüttenjazz/NN', 0.537042498588562),\n",
       " ('german/NN', 0.5326942801475525)]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Analogy with normalized Vector\n",
    "vec_france_norm = wv.word_vec('france/NN', use_norm=True)\n",
    "vec_paris_norm = wv.word_vec('paris/NN', use_norm=True)\n",
    "vec_berlin_norm = wv.word_vec('berlin/NN', use_norm=True)\n",
    "vec_germany_norm = wv.word_vec('germany/NN', use_norm=True)\n",
    "vec_country_norm = wv.word_vec('country/NN', use_norm=True)\n",
    "print(\"france is to paris as berlin is to ?\")\n",
    "wv.most_similar([vec_france_norm - vec_paris_norm + vec_berlin_norm])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cosine_similarities of france and paris\n",
      "[0.62629485] 0.37370521250384203\n",
      "cosine_similarities of france and berlin\n",
      "[0.26217574] 0.7378242844644337\n",
      "cosine_similarities of france and germany\n",
      "[0.56096226] 0.4390377899399447\n",
      "cosine_similarities of france and country\n",
      "[0.35918537] 0.6408146341093731\n"
     ]
    }
   ],
   "source": [
    "# Cosine Similarities\n",
    "print(\"cosine_similarities of france and paris\")\n",
    "print(wv.cosine_similarities(vec_france_norm, [vec_paris_norm]),wv.distance(\"france/NN\", \"paris/NN\"))\n",
    "print(\"cosine_similarities of france and berlin\")\n",
    "print(wv.cosine_similarities(vec_france_norm, [vec_berlin_norm]),wv.distance(\"france/NN\", \"berlin/NN\"))\n",
    "print(\"cosine_similarities of france and germany\")\n",
    "print(wv.cosine_similarities(vec_france_norm, [vec_germany_norm]),wv.distance(\"france/NN\", \"germany/NN\"))\n",
    "print(\"cosine_similarities of france and country\")\n",
    "print(wv.cosine_similarities(vec_france_norm, [vec_country_norm]),wv.distance(\"france/NN\", \"country/NN\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Man is to Woman what King is to ?\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('king/NN', 0.7021986246109009),\n",
       " ('queen/NN', 0.5920202732086182),\n",
       " ('monarch/NN', 0.5383858680725098),\n",
       " ('woman/NN', 0.4814680218696594),\n",
       " ('crown/NN', 0.4538986086845398),\n",
       " ('ingwenyama/NN', 0.436950147151947),\n",
       " ('princess/NN', 0.43597322702407837),\n",
       " ('empress/NN', 0.42599907517433167),\n",
       " ('regnant/NN', 0.4184303283691406),\n",
       " ('ranavalona/NN', 0.416481077671051)]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Analogy\n",
    "print(\"king is to man what woman is to ?\")\n",
    "#wv.most_similar([wv['man/NN'] - wv['woman/NN'] + wv['king/NN']])\n",
    "wv.most_similar([wv['king/NN'] - wv['man/NN'] + wv['woman/NN']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "paris is to france as germany is to ?\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('berlin/NN', 0.7753599882125854),\n",
       " ('germany/NN', 0.7352864742279053),\n",
       " ('munich/JJ', 0.7241991758346558),\n",
       " ('berlin/VB', 0.7004410028457642),\n",
       " ('cologne/NN', 0.6728582382202148),\n",
       " ('düsseldorf/NN', 0.6541168093681335),\n",
       " ('bonn/NN', 0.6338502168655396),\n",
       " ('dresden/NN', 0.6333985328674316),\n",
       " ('hamburg/NN', 0.6157830953598022),\n",
       " ('leipzig/NN', 0.6134828329086304)]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Analogy\n",
    "print(\"paris is to france as germany is to ?\")\n",
    "wv.most_similar([wv['paris/NN'] - wv['france/NN'] + wv['germany/NN']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat is to mammal as sparrow is to ?\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('cat/NN', 0.7435729503631592),\n",
       " ('dog/NN', 0.5758434534072876),\n",
       " ('kitten/NN', 0.551855742931366),\n",
       " ('bird/NN', 0.5491441488265991),\n",
       " ('kitty/NN', 0.5458417534828186),\n",
       " ('meow/VB', 0.5401268601417542),\n",
       " ('meow/NN', 0.5142310261726379),\n",
       " ('poodle/NN', 0.5134133100509644),\n",
       " ('goldfish/NN', 0.5111803412437439),\n",
       " ('slinky/JJ', 0.49928945302963257)]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Analogy\n",
    "print(\"cat is to mammal as sparrow is to ?\")\n",
    "wv.most_similar([wv['cat/NN'] - wv['mammal/NN'] + wv['bird/NN']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grass is to green as sky is to ?\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('green/NN', 0.576596736907959),\n",
       " ('sky/NN', 0.5435831546783447),\n",
       " ('green/JJ', 0.3984556496143341),\n",
       " ('green/VB', 0.3885582387447357),\n",
       " ('jordannick/NN', 0.3508602976799011),\n",
       " ('horizon/NN', 0.3487999737262726),\n",
       " ('ukip/NN', 0.3445552587509155),\n",
       " ('percomi/NN', 0.34198832511901855),\n",
       " ('seneley/NN', 0.3393542170524597),\n",
       " ('sunlit/NN', 0.32632747292518616)]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Analogy\n",
    "print(\"grass is to green as sky is to ?\")\n",
    "wv.most_similar([wv['sky/NN'] - wv['blue/NN'] + wv['green/NN']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "athens is to greece as baghdad is to ?\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('afghanistan/NN', 0.7056152820587158),\n",
       " ('afghan/NN', 0.6274094581604004),\n",
       " ('nangarhar/NN', 0.6010676622390747),\n",
       " ('taliban/JJ', 0.5929509401321411),\n",
       " ('kandahar/NN', 0.5881943702697754),\n",
       " ('taliban/VB', 0.5868856906890869),\n",
       " ('roghni/NN', 0.5827623009681702),\n",
       " ('khost/NN', 0.5813905000686646),\n",
       " ('kabul/NN', 0.5794689655303955),\n",
       " ('helmand/NN', 0.5781930685043335)]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Analogy\n",
    "print(\"athens is to greece as baghdad is to ?\")\n",
    "wv.most_similar([wv['athens/NN'] - wv['greece/NN'] + wv['afghanistan/NN']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('country/NN', 0.9999998807907104),\n",
       " ('nation/NN', 0.6845932602882385),\n",
       " ('region/NN', 0.5479593873023987),\n",
       " ('continent/NN', 0.54496169090271),\n",
       " ('europe/NN', 0.5181665420532227),\n",
       " ('have/VB', 0.4689757823944092),\n",
       " ('globally/RB', 0.43926775455474854),\n",
       " ('abroad/RB', 0.4374126195907593),\n",
       " ('market/NN', 0.4372479021549225),\n",
       " ('number/NN', 0.4358119070529938)]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wv.most_similar([wv[\"country/NN\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('capital/NN', 1.0),\n",
       " ('investment/NN', 0.5486246943473816),\n",
       " ('asset/NN', 0.4636381268501282),\n",
       " ('territory/NN', 0.45464810729026794),\n",
       " ('investor/NN', 0.4461580812931061),\n",
       " ('bank/NN', 0.4335326552391052),\n",
       " ('economy/NN', 0.4294159412384033),\n",
       " ('province/NN', 0.4275493323802948),\n",
       " ('region/NN', 0.4241411089897156),\n",
       " ('xingwang/NN', 0.42348968982696533)]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wv.most_similar([wv[\"capital/NN\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('paris/NN', 0.5917073488235474),\n",
       " ('orsay/JJ', 0.4863584637641907),\n",
       " ('colette/VB', 0.4663430452346802),\n",
       " ('montparnasse/VB', 0.4581751525402069),\n",
       " ('montparnasse/JJ', 0.45304393768310547),\n",
       " ('gustave/JJ', 0.45213115215301514),\n",
       " ('léonce/VB', 0.4514530599117279),\n",
       " ('delpire/NN', 0.4500682055950165),\n",
       " ('parisian/JJ', 0.4495515823364258),\n",
       " ('romantique/JJ', 0.44724446535110474)]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wv.most_similar([wv[\"paris/NN\"]-wv[\"capital/NN\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('bern/NN', 0.5901567935943604),\n",
       " ('bern/JJ', 0.5297247171401978),\n",
       " ('luzern/NN', 0.45419546961784363),\n",
       " ('jürg/NN', 0.45301809906959534),\n",
       " ('zurich/JJ', 0.4391050338745117),\n",
       " ('bern/VB', 0.41643407940864563),\n",
       " ('lüscher/NN', 0.4157090187072754),\n",
       " ('zürich/NN', 0.41449370980262756),\n",
       " ('basel/JJ', 0.4126679301261902),\n",
       " ('herisau/NN', 0.4125199019908905)]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wv.most_similar([wv[\"bern/NN\"]-wv[\"capital/NN\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('switzerland/NN', 0.5533241033554077),\n",
       " ('italy/NN', 0.4750353991985321),\n",
       " ('belgium/NN', 0.4626234173774719),\n",
       " ('europe/NN', 0.4177972078323364),\n",
       " ('germany/NN', 0.41732004284858704),\n",
       " ('argentina/NN', 0.4152482748031616),\n",
       " ('finland/NN', 0.4150034487247467),\n",
       " ('econometriclink/VB', 0.3965272307395935),\n",
       " ('bioavena/NN', 0.3937831521034241),\n",
       " ('scandinavia/RB', 0.39317047595977783)]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wv.most_similar([wv[\"switzerland/NN\"]-wv[\"bern/NN\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.30662431795333833"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wv.distance(\"dog/NN\", \"dogs/NN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.6933757], dtype=float32)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wv.cosine_similarities(wv[\"dog/NN\"],[wv[\"dogs/NN\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4661005163408918"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wv.distance(\"switzerland/NN\", \"bern/NN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.5338995], dtype=float32)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wv.cosine_similarities(wv[\"switzerland/NN\"],[wv[\"bern/NN\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7524347683335195"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wv.distance(\"paris/NN\", \"bern/NN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.24756521], dtype=float32)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wv.cosine_similarities(wv[\"paris/NN\"],[wv[\"bern/NN\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.03346416], dtype=float32)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wv.cosine_similarities(wv[\"paris/NN\"],[wv[\"dog/NN\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analogy\n",
    "print(\"capital + science\")\n",
    "wv.most_similar([wv['capital/NN'] + wv['science/NN']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wv.cosine_similarities(wv[\"education/NN\"], [wv[\"natality/NN\"],wv[\"salubrity/NN\"],wv[\"economy/NN\"]]\n",
    "\n",
    "#wv.distance(\"education\",\"natality\")\n",
    "\n",
    "# education, natality, salubrity, economy\n",
    "\n",
    "#wv.most_similar_cosmul(positive=[\"doctor\",\"woman\"], negative=[\"man\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
