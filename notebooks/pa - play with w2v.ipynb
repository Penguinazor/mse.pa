{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn on Auto-Complete\n",
    "%config IPCompleter.greedy=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start logging process at root level\n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "logging.root.setLevel(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model and dictionary\n",
    "#model_id_current = 99999\n",
    "#model_path_current = \"models/enwiki-full-dict-\"+str(model_id_current)+\".model\"\n",
    "model_path_current = \"models/enwiki-20190319-lemmatized-99999.model\"\n",
    "\n",
    "dictionary_full_wikien_lem_path = \"dictionaries/enwiki-20190409-dict-lemmatized.txt.bz2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-04-17 18:22:20,635 : INFO : 'pattern' package found; tag filters are available for English\n",
      "2019-04-17 18:22:20,651 : INFO : loading Word2Vec object from models/enwiki-20190319-lemmatized-99999.model\n",
      "2019-04-17 18:22:29,416 : INFO : loading vocabulary recursively from models/enwiki-20190319-lemmatized-99999.model.vocabulary.* with mmap=r\n",
      "2019-04-17 18:22:29,420 : INFO : loading wv recursively from models/enwiki-20190319-lemmatized-99999.model.wv.* with mmap=r\n",
      "2019-04-17 18:22:29,422 : INFO : loading vectors from models/enwiki-20190319-lemmatized-99999.model.wv.vectors.npy with mmap=r\n",
      "2019-04-17 18:22:29,433 : INFO : setting ignored attribute vectors_norm to None\n",
      "2019-04-17 18:22:29,435 : INFO : loading trainables recursively from models/enwiki-20190319-lemmatized-99999.model.trainables.* with mmap=r\n",
      "2019-04-17 18:22:29,437 : INFO : loading syn1neg from models/enwiki-20190319-lemmatized-99999.model.trainables.syn1neg.npy with mmap=r\n",
      "2019-04-17 18:22:29,439 : INFO : setting ignored attribute cum_table to None\n",
      "2019-04-17 18:22:29,441 : INFO : loaded models/enwiki-20190319-lemmatized-99999.model\n"
     ]
    }
   ],
   "source": [
    "# Load word2vec model\n",
    "from gensim.models import Word2Vec\n",
    "model = Word2Vec.load(model_path_current, mmap='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dog/NN\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Custom lemmatizer function to play with word\n",
    "from gensim.utils import lemmatize\n",
    "#vocabulary = set(wv.index2word)\n",
    "def lem(word):\n",
    "    try:\n",
    "        return lemmatize(word)[0].decode(\"utf-8\")\n",
    "    except:\n",
    "        pass\n",
    "        \n",
    "print(lem(\"dog\"))\n",
    "print(lem(\"that\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-04-16 16:50:29,358 : INFO : precomputing L2-norms of word weight vectors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most similar to woman/NN\n",
      "[('lesbian/NN', 0.46007344126701355), ('man/NN', 0.4519272744655609), ('transwoman/NN', 0.45071157813072205), ('feminist/NN', 0.4451548755168915), ('feminist/VB', 0.4357849955558777), ('womanhood/NN', 0.4307554364204407), ('sztokman/NN', 0.3955826163291931), ('englishwoman/NN', 0.395127534866333), ('feminist/JJ', 0.3936055898666382), ('antifeminist/NN', 0.39345377683639526)]\n",
      "\n",
      "Most similar to doctor/NN\n",
      "[('dentist/NN', 0.5012549161911011), ('physician/NN', 0.4942778944969177), ('dolittle/RB', 0.4727567732334137), ('veterinarian/NN', 0.4650288224220276), ('zhivago/VB', 0.4592878222465515), ('who/NN', 0.4559624195098877), ('zhivago/JJ', 0.4459368586540222), ('doolot/NN', 0.4328805208206177), ('pulmonologist/NN', 0.4282873868942261), ('internist/NN', 0.4256983995437622)]\n"
     ]
    }
   ],
   "source": [
    "# Testing similarity\n",
    "print(\"Most similar to\",lem(\"woman\"))\n",
    "print(model.wv.most_similar(lem(\"woman\")))\n",
    "print(\"\\nMost similar to\",\"doctor/NN\")\n",
    "print(model.wv.most_similar(\"doctor/NN\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving some ram by using the KeyedVectors instance\n",
    "wv = model.wv\n",
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most similar to woman/NN\n",
      "[('lesbian/NN', 0.46007344126701355), ('man/NN', 0.4519272744655609), ('transwoman/NN', 0.45071157813072205), ('feminist/NN', 0.4451548755168915), ('feminist/VB', 0.4357849955558777), ('womanhood/NN', 0.4307554364204407), ('sztokman/NN', 0.3955826163291931), ('englishwoman/NN', 0.395127534866333), ('feminist/JJ', 0.3936055898666382), ('antifeminist/NN', 0.39345377683639526)]\n",
      "\n",
      "Most similar to man/NN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rclaret/anaconda3/envs/py36/lib/python3.6/site-packages/ipykernel_launcher.py:5: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  \"\"\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('woman/NN', 0.4519272446632385), ('thug/NN', 0.40778353810310364), ('boy/NN', 0.3781570494174957), ('nudy/NN', 0.37579405307769775), ('roynell/VB', 0.3751065731048584), ('nowhere/NN', 0.3721665143966675), ('delmon/VB', 0.3710464835166931), ('wrightwood/VB', 0.3666095733642578), ('fogey/NN', 0.3656005859375), ('taolu/RB', 0.3626784682273865)]\n",
      "\n",
      "Most similar to doctor/NN\n",
      "[('dentist/NN', 0.5012549161911011), ('physician/NN', 0.4942778944969177), ('dolittle/RB', 0.4727567732334137), ('veterinarian/NN', 0.4650288224220276), ('zhivago/VB', 0.4592878222465515), ('who/NN', 0.4559624195098877), ('zhivago/JJ', 0.4459368586540222), ('doolot/NN', 0.4328805208206177), ('pulmonologist/NN', 0.4282873868942261), ('internist/NN', 0.4256983995437622)]\n",
      "\n",
      "Most similar to doctor/NN cosmul\n",
      "[('dentist/NN', 0.750626802444458), ('physician/NN', 0.747138261795044), ('dolittle/RB', 0.7363777160644531), ('veterinarian/NN', 0.7325137257575989), ('zhivago/VB', 0.7296432256698608), ('who/NN', 0.7279804944992065), ('zhivago/JJ', 0.7229677438735962), ('doolot/NN', 0.7164396047592163), ('pulmonologist/NN', 0.7141430377960205), ('internist/NN', 0.7128485441207886)]\n"
     ]
    }
   ],
   "source": [
    "# Testing similarity with KeyedVectors\n",
    "print(\"Most similar to\",lem(\"woman\"))\n",
    "print(wv.most_similar(lem(\"woman\")))\n",
    "print(\"\\nMost similar to\",lem(\"man\"))\n",
    "print(wv.wv.most_similar(lem(\"man\")))\n",
    "print(\"\\nMost similar to\",\"doctor/NN\")\n",
    "print(wv.most_similar(\"doctor/NN\"))\n",
    "print(\"\\nMost similar to\",\"doctor/NN\",\"cosmul\")\n",
    "print(wv.most_similar_cosmul(positive=[\"doctor/NN\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "similarity of doctor + woman - man\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('midwife/NN', 0.4707856774330139),\n",
       " ('gynaecologist/NN', 0.45252716541290283),\n",
       " ('dentist/NN', 0.44752874970436096),\n",
       " ('nurse/NN', 0.4470706284046173),\n",
       " ('gynecologist/NN', 0.4430723786354065),\n",
       " ('obstetrics/JJ', 0.4371750056743622),\n",
       " ('anesthetist/NN', 0.4341370463371277),\n",
       " ('obstetrician/NN', 0.4318876564502716),\n",
       " ('pharmacist/NN', 0.429206520318985),\n",
       " ('midwifery/NN', 0.426381915807724)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"similarity of doctor + woman - man\")\n",
    "wv.most_similar(positive=[\"doctor/NN\",\"woman/NN\"], negative=[\"man/NN\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cosmul of doctor + woman - man\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('midwife/NN', 0.8986764550209045),\n",
       " ('gynaecologist/NN', 0.8874868750572205),\n",
       " ('midwifery/NN', 0.8800663948059082),\n",
       " ('anesthetist/NN', 0.8751559853553772),\n",
       " ('obstetrics/JJ', 0.8749768733978271),\n",
       " ('pediatrician/NN', 0.8707965612411499),\n",
       " ('obstetrician/NN', 0.8701598048210144),\n",
       " ('nurse/NN', 0.8692474961280823),\n",
       " ('gynecologist/NN', 0.8639448881149292),\n",
       " ('midwive/VB', 0.8639071583747864)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get cosmul of logic\n",
    "print(\"cosmul of doctor + woman - man\")\n",
    "wv.most_similar_cosmul(positive=[\"doctor/NN\",\"woman/NN\"], negative=[\"man/NN\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get item dog\n"
     ]
    }
   ],
   "source": [
    "# Ways to retrive word vector\n",
    "print(\"Get item dog\")\n",
    "vec_dog = wv.__getitem__(\"dog/NN\")\n",
    "vec_dog = wv.get_vector(\"dog/NN\")\n",
    "vec_dog = wv.word_vec(\"dog/NN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similar to dog vector\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('dog/NN', 0.9999999403953552),\n",
       " ('rottweiler/NN', 0.6149188876152039),\n",
       " ('poodle/NN', 0.5928210020065308),\n",
       " ('dogs/NN', 0.5638971924781799),\n",
       " ('puppy/NN', 0.556917667388916),\n",
       " ('dachshund/NN', 0.55369633436203),\n",
       " ('pekingese/JJ', 0.5461680889129639),\n",
       " ('pet/VB', 0.5417574644088745),\n",
       " ('bullmastiff/NN', 0.5413404107093811),\n",
       " ('kennel/VB', 0.5349524021148682)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get similar words to vector\n",
    "wv.similar_by_vector(vector=vec_dog, topn=10, restrict_vocab=None)\n",
    "print(\"Similar to dog vector\")\n",
    "wv.most_similar(positive=[vec_dog])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "closer to dog than cat\n",
      "['pet/NN', 'hound/NN', 'kennel/NN', 'puppy/NN', 'kitten/NN', 'canine/JJ', 'beagle/NN', 'retriever/NN', 'dog/VB', 'dachshund/NN', 'feline/JJ', 'leash/NN', 'spaniel/NN', 'sheepdog/NN', 'poodle/NN', 'bichon/NN', 'komondor/NN', 'mastiff/NN', 'pug/NN', 'feline/NN', 'pet/VB', 'longhaired/JJ', 'dogs/JJ', 'rowlf/VB', 'pinscher/NN', 'rottweiler/NN', 'dogs/NN', 'coonhound/NN', 'sniffer/JJ', 'dachshund/VB', 'kennel/VB', 'rottweiler/JJ', 'mangy/JJ', 'euthanization/NN', 'leashed/JJ', 'pug/JJ', 'bullmastiff/NN', 'pekingese/JJ', 'akbash/NN', 'weimaraner/NN', 'pekingese/NN', 'pukin/NN', 'polydactyl/JJ']\n",
      "\n",
      "closer to cat than dog\n",
      "['anthropomorphic/JJ', 'kitten/NN', 'feline/JJ', 'tabby/JJ', 'feline/NN', 'fraggle/NN', 'dogs/JJ', 'tanuki/NN', 'mangy/JJ', 'meow/VB', 'wampus/NN', 'pekingese/JJ', 'nintendogs/JJ', 'scaredy/NN', 'zingano/NN']\n"
     ]
    }
   ],
   "source": [
    "# closer to __ than __\n",
    "print(\"closer to dog than cat\")\n",
    "print(wv.words_closer_than(\"dog/NN\", \"cat/NN\"))\n",
    "print(\"\\ncloser to cat than dog\")\n",
    "print(wv.words_closer_than(\"cat/NN\", \"dog/NN\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalized Vector\n",
    "vec_king_norm = wv.word_vec(\"king/NN\", use_norm=True)\n",
    "# Not normalized vectore\n",
    "vec_king_unnorm = wv.word_vec(\"king/NN\", use_norm=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('martenetz/JJ', 0.25446975231170654),\n",
       " ('chinalink/VB', 0.23597362637519836),\n",
       " ('rosenstreich/JJ', 0.23545649647712708),\n",
       " ('kibbutznikiyot/NN', 0.23487138748168945),\n",
       " ('plastic/NN', 0.23192651569843292),\n",
       " ('unsightliest/JJ', 0.23074200749397278),\n",
       " ('gyoku/JJ', 0.23043902218341827),\n",
       " ('pjp/NN', 0.22816041111946106),\n",
       " ('молива/NN', 0.22780275344848633),\n",
       " ('oppotion/NN', 0.2250169962644577)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wv.most_similar(positive=[vec_king_norm], negative=[vec_king_unnorm])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300,)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get vector shape\n",
    "vec_king_unnorm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "similar to random vector\n",
      "[('dagana/NN', 0.310502290725708), ('boeny/NN', 0.30554085969924927), ('fitovinany/NN', 0.30136212706565857), ('qasimov/JJ', 0.2948823571205139), ('mangoro/NN', 0.29376664757728577), ('melaky/JJ', 0.293718159198761), ('dalila/NN', 0.28584954142570496), ('atsinanana/RB', 0.28495872020721436), ('brčko/JJ', 0.2835693955421448), ('interexport/NN', 0.2830585539340973)]\n",
      "\n",
      " similar to nomalized random vector\n",
      "[('dagana/NN', 0.310502290725708), ('boeny/NN', 0.30554085969924927), ('fitovinany/NN', 0.30136212706565857), ('qasimov/JJ', 0.2948823571205139), ('mangoro/NN', 0.29376664757728577), ('melaky/JJ', 0.293718159198761), ('dalila/NN', 0.28584954142570496), ('atsinanana/RB', 0.28495872020721436), ('brčko/JJ', 0.2835693955421448), ('interexport/NN', 0.2830585539340973)]\n"
     ]
    }
   ],
   "source": [
    "# Generate random vector\n",
    "import numpy as np\n",
    "vec_random = np.random.rand(300,)\n",
    "vec_random_norm = vec_random / vec_random.max(axis=0)\n",
    "print(\"similar to random vector\")\n",
    "print(wv.most_similar(positive=[vec_random]))\n",
    "print(\"\\n similar to nomalized random vector\")\n",
    "print(wv.most_similar(positive=[vec_random_norm]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "similarity from a normalized random vector to normalized vector of king\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('dagana/NN', 0.31837376952171326),\n",
       " ('boeny/NN', 0.3109041750431061),\n",
       " ('fitovinany/NN', 0.30090072751045227),\n",
       " ('mangoro/NN', 0.2952515184879303),\n",
       " ('melaky/JJ', 0.2938075065612793),\n",
       " ('qasimov/JJ', 0.29035305976867676),\n",
       " ('atsinanana/RB', 0.2888091504573822),\n",
       " ('taoudénit/NN', 0.28652405738830566),\n",
       " ('interexport/NN', 0.2856239676475525),\n",
       " ('dalila/NN', 0.28082406520843506)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get similarity from a random vector and normilized king vector\n",
    "print(\"similarity from a normalized random vector to normalized vector of king\")\n",
    "wv.most_similar(positive=[vec_random_norm,vec_king_norm])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "similarity from a random vector to unormalized vector of king\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('king/NN', 0.8547921776771545),\n",
       " ('hattusili/VB', 0.44188767671585083),\n",
       " ('inshushinak/VB', 0.4376552402973175),\n",
       " ('neustrium/NN', 0.43171319365501404),\n",
       " ('usurper/NN', 0.4287143349647522),\n",
       " ('hengal/JJ', 0.42845696210861206),\n",
       " ('uṣur/NN', 0.426206111907959),\n",
       " ('chlothar/VB', 0.424801230430603),\n",
       " ('indravarman/NN', 0.42459505796432495),\n",
       " ('bhuvanaikabahu/NN', 0.42417895793914795)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get similarity from a random vector and unormalized king vector\n",
    "print(\"similarity from a random vector to unormalized vector of king\")\n",
    "wv.most_similar(positive=[vec_random,vec_king_unnorm])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cosine similarity from a random vector to unormalized vector of king\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-0.03458707])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get cosine similarities from a vector to an array of vectors\n",
    "print(\"cosine similarity from a random vector to unormalized vector of king\")\n",
    "wv.cosine_similarities(vec_random, [vec_king_unnorm])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'wv' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-ca53cb982086>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Tests analogies based on a text file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0manalogy_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'datasets/questions-words.txt'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdummy4unknown\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;31m#print(analogy_scores)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'wv' is not defined"
     ]
    }
   ],
   "source": [
    "# Tests analogies based on a text file\n",
    "\n",
    "analogy_scores = wv.accuracy('datasets/questions-words.txt',dummy4unknown=False)\n",
    "#print(analogy_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The the distance of two words\n",
    "print(\"distance between dog and cat\")\n",
    "wv.distance(\"dog/NN\",\"cat/NN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the distance of a word for the list of word\n",
    "print(\"distance from dog to king and cat\")\n",
    "wv.distances(\"dog/NN\",[\"king/NN\",\"cat/NN\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate pairs of words\n",
    "#wv.evaluate_word_pairs(\"datasets/SimLex-999.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get sentence similarities\n",
    "\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim.utils import simple_preprocess    \n",
    "\n",
    "def tokemmized(sentence, vocabulary):\n",
    "    tokens = [lem(word) for word in simple_preprocess(sentence)]\n",
    "    return [word for word in tokens if word in vocabulary]   \n",
    "\n",
    "def compute_sentence_similarity(sentence_1, sentence_2, model_wv):\n",
    "    vocabulary = set(model_wv.index2word)\n",
    "    tokens_1 = tokemmized(sentence_1, vocabulary)\n",
    "    tokens_2 = tokemmized(sentence_2, vocabulary)\n",
    "    del vocabulary\n",
    "    print(tokens_1, tokens_2)\n",
    "    return model_wv.n_similarity(tokens_1, tokens_2)\n",
    "\n",
    "similarity = compute_sentence_similarity('this is a sentence', 'this is also a sentence', wv)\n",
    "print(similarity,\"\\n\")\n",
    "\n",
    "similarity = compute_sentence_similarity('the cat is a mammal', 'the bird is a aves', wv)\n",
    "print(similarity,\"\\n\")\n",
    "\n",
    "similarity = compute_sentence_similarity('the cat is a mammal', 'the dog is a mammal', wv)\n",
    "print(similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analogy with not normalized vectors\n",
    "print(\"france is to france as berlin is to ?\")\n",
    "wv.most_similar([wv['france/NN'] - wv['paris/NN'] + wv['berlin/NN']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analogy with normalized Vector\n",
    "vec_france_norm = wv.word_vec(lem('France'), use_norm=True)\n",
    "vec_paris_norm = wv.word_vec(lem('Paris'), use_norm=True)\n",
    "vec_berlin_norm = wv.word_vec(lem('Berlin'), use_norm=True)\n",
    "vec_germany_norm = wv.word_vec(lem('Germany'), use_norm=True)\n",
    "vec_country_norm = wv.word_vec(lem('country'), use_norm=True)\n",
    "print(\"france is to france as berlin is to ?\")\n",
    "wv.most_similar([vec_france_norm + vec_paris_norm - vec_country_norm])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cosine Similarities\n",
    "print(\"cosine_similarities of france and paris\")\n",
    "print(wv.cosine_similarities(vec_france_norm, [vec_paris_norm]))\n",
    "print(\"cosine_similarities of france and berlin\")\n",
    "print(wv.cosine_similarities(vec_france_norm, [vec_berlin_norm]))\n",
    "print(\"cosine_similarities of france and country\")\n",
    "print(wv.cosine_similarities(vec_france_norm, [vec_country_norm]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analogy\n",
    "print(\"paris is to france as germany is to ?\")\n",
    "wv.most_similar([wv['france/NN'] + wv['germany/NN'] - wv['paris/NN']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analogy\n",
    "print(\"cat is to mammal as sparrow is to ?\")\n",
    "wv.most_similar([wv['mammal/NN'] - wv['sparrow/NN'] + wv['cat/NN']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analogy\n",
    "print(\"grass is to green as sky is to ?\")\n",
    "wv.most_similar([wv['green/NN'] - wv['sky/NN'] + wv['grass/NN']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analogy\n",
    "print(\"athens is to greece as baghdad is to ?\")\n",
    "wv.most_similar([wv['athens/NN'] - wv['greece/NN'] + wv['baghdad/NN']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
