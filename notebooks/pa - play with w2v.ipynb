{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn on Auto-Complete\n",
    "%config IPCompleter.greedy=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start logging process at root level\n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "logging.root.setLevel(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model and dictionary\n",
    "model_id_current = 99999\n",
    "model_path_current = \"models/enwiki-full-dict-\"+str(model_id_current)+\".model\"\n",
    "\n",
    "dictionary_full_wikien_lem_path = \"dictionaries/enwiki-english-lemmatized.txt.bz2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-04-08 09:50:41,762 : INFO : 'pattern' package found; tag filters are available for English\n",
      "2019-04-08 09:50:41,767 : INFO : loading Word2Vec object from models/enwiki-full-dict-99999.model\n",
      "2019-04-08 09:50:45,989 : INFO : loading vocabulary recursively from models/enwiki-full-dict-99999.model.vocabulary.* with mmap=r\n",
      "2019-04-08 09:50:45,997 : INFO : loading wv recursively from models/enwiki-full-dict-99999.model.wv.* with mmap=r\n",
      "2019-04-08 09:50:46,004 : INFO : loading vectors from models/enwiki-full-dict-99999.model.wv.vectors.npy with mmap=r\n",
      "2019-04-08 09:50:46,057 : INFO : setting ignored attribute vectors_norm to None\n",
      "2019-04-08 09:50:46,059 : INFO : loading trainables recursively from models/enwiki-full-dict-99999.model.trainables.* with mmap=r\n",
      "2019-04-08 09:50:46,060 : INFO : loading syn1neg from models/enwiki-full-dict-99999.model.trainables.syn1neg.npy with mmap=r\n",
      "2019-04-08 09:50:46,063 : INFO : setting ignored attribute cum_table to None\n",
      "2019-04-08 09:50:46,064 : INFO : loaded models/enwiki-full-dict-99999.model\n"
     ]
    }
   ],
   "source": [
    "# Load word2vec model\n",
    "from gensim.models import Word2Vec\n",
    "model = Word2Vec.load(model_path_current, mmap='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dog/NN\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Custom lemmatizer function to play with word\n",
    "from gensim.utils import lemmatize\n",
    "#vocabulary = set(wv.index2word)\n",
    "def lem(word):\n",
    "    try:\n",
    "        return lemmatize(word)[0].decode(\"utf-8\")\n",
    "    except:\n",
    "        pass\n",
    "        \n",
    "print(lem(\"dog\"))\n",
    "print(lem(\"that\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-04-08 09:50:49,331 : INFO : precomputing L2-norms of word weight vectors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most similar to woman/NN\n",
      "[('lesbian/NN', 0.4600733518600464), ('man/NN', 0.4519272744655609), ('transwoman/NN', 0.45071160793304443), ('feminist/NN', 0.4451548457145691), ('feminist/VB', 0.4357849955558777), ('womanhood/NN', 0.4307554364204407), ('sztokman/NN', 0.3955826163291931), ('englishwoman/NN', 0.39512747526168823), ('feminist/JJ', 0.3936055898666382), ('antifeminist/NN', 0.39345383644104004)]\n",
      "\n",
      "Most similar to doctor/NN\n",
      "[('dentist/NN', 0.5012550354003906), ('physician/NN', 0.4942779242992401), ('dolittle/RB', 0.47275668382644653), ('veterinarian/NN', 0.4650288224220276), ('zhivago/VB', 0.4592878222465515), ('who/NN', 0.4559624195098877), ('zhivago/JJ', 0.4459368586540222), ('doolot/NN', 0.43288061022758484), ('pulmonologist/NN', 0.4282873570919037), ('internist/NN', 0.4256983995437622)]\n"
     ]
    }
   ],
   "source": [
    "# Testing similarity\n",
    "print(\"Most similar to\",lem(\"woman\"))\n",
    "print(model.wv.most_similar(lem(\"woman\")))\n",
    "print(\"\\nMost similar to\",\"doctor/NN\")\n",
    "print(model.wv.most_similar(\"doctor/NN\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving some ram by using the KeyedVectors instance\n",
    "wv = model.wv\n",
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most similar to woman/NN\n",
      "[('lesbian/NN', 0.4600733518600464), ('man/NN', 0.4519272744655609), ('transwoman/NN', 0.45071160793304443), ('feminist/NN', 0.4451548457145691), ('feminist/VB', 0.4357849955558777), ('womanhood/NN', 0.4307554364204407), ('sztokman/NN', 0.3955826163291931), ('englishwoman/NN', 0.39512747526168823), ('feminist/JJ', 0.3936055898666382), ('antifeminist/NN', 0.39345383644104004)]\n",
      "\n",
      "Most similar to man/NN\n",
      "[('woman/NN', 0.4519272744655609), ('thug/NN', 0.40778350830078125), ('boy/NN', 0.3781570792198181), ('nudy/NN', 0.37579411268234253), ('roynell/VB', 0.3751066327095032), ('nowhere/NN', 0.3721664547920227), ('delmon/VB', 0.3710464537143707), ('wrightwood/VB', 0.3666095435619354), ('fogey/NN', 0.3656006157398224), ('taolu/RB', 0.3626784086227417)]\n",
      "\n",
      "Most similar to doctor/NN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:5: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  \"\"\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('dentist/NN', 0.5012550354003906), ('physician/NN', 0.4942779242992401), ('dolittle/RB', 0.47275668382644653), ('veterinarian/NN', 0.4650288224220276), ('zhivago/VB', 0.4592878222465515), ('who/NN', 0.4559624195098877), ('zhivago/JJ', 0.4459368586540222), ('doolot/NN', 0.43288061022758484), ('pulmonologist/NN', 0.4282873570919037), ('internist/NN', 0.4256983995437622)]\n",
      "\n",
      "Most similar to doctor/NN cosmul\n",
      "[('dentist/NN', 0.750626802444458), ('physician/NN', 0.747138261795044), ('dolittle/RB', 0.7363775968551636), ('veterinarian/NN', 0.7325136661529541), ('zhivago/VB', 0.7296431660652161), ('who/NN', 0.7279804944992065), ('zhivago/JJ', 0.7229676842689514), ('doolot/NN', 0.7164396643638611), ('pulmonologist/NN', 0.7141429781913757), ('internist/NN', 0.7128485441207886)]\n"
     ]
    }
   ],
   "source": [
    "# Testing similarity with KeyedVectors\n",
    "print(\"Most similar to\",lem(\"woman\"))\n",
    "print(wv.most_similar(lem(\"woman\")))\n",
    "print(\"\\nMost similar to\",lem(\"man\"))\n",
    "print(wv.wv.most_similar(lem(\"man\")))\n",
    "print(\"\\nMost similar to\",\"doctor/NN\")\n",
    "print(wv.most_similar(\"doctor/NN\"))\n",
    "print(\"\\nMost similar to\",\"doctor/NN\",\"cosmul\")\n",
    "print(wv.most_similar_cosmul(positive=[\"doctor/NN\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "similarity of doctor + woman - man\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('midwife/NN', 0.4707856774330139),\n",
       " ('gynaecologist/NN', 0.4525271952152252),\n",
       " ('dentist/NN', 0.4475286900997162),\n",
       " ('nurse/NN', 0.4470705986022949),\n",
       " ('gynecologist/NN', 0.4430723786354065),\n",
       " ('obstetrics/JJ', 0.4371750056743622),\n",
       " ('anesthetist/NN', 0.4341369867324829),\n",
       " ('obstetrician/NN', 0.43188774585723877),\n",
       " ('pharmacist/NN', 0.4292064905166626),\n",
       " ('midwifery/NN', 0.4263818860054016)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"similarity of doctor + woman - man\")\n",
    "wv.most_similar(positive=[\"doctor/NN\",\"woman/NN\"], negative=[\"man/NN\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cosmul of doctor + woman - man\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('midwife/NN', 0.8986763954162598),\n",
       " ('gynaecologist/NN', 0.8874867558479309),\n",
       " ('midwifery/NN', 0.8800663352012634),\n",
       " ('anesthetist/NN', 0.8751558661460876),\n",
       " ('obstetrics/JJ', 0.8749769330024719),\n",
       " ('pediatrician/NN', 0.8707965612411499),\n",
       " ('obstetrician/NN', 0.8701597452163696),\n",
       " ('nurse/NN', 0.8692474365234375),\n",
       " ('gynecologist/NN', 0.8639448285102844),\n",
       " ('midwive/VB', 0.8639072179794312)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get cosmul of logic\n",
    "print(\"cosmul of doctor + woman - man\")\n",
    "wv.most_similar_cosmul(positive=[\"doctor/NN\",\"woman/NN\"], negative=[\"man/NN\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get item dog\n"
     ]
    }
   ],
   "source": [
    "# Ways to retrive word vector\n",
    "print(\"Get item dog\")\n",
    "vec_dog = wv.__getitem__(\"dog/NN\")\n",
    "vec_dog = wv.get_vector(\"dog/NN\")\n",
    "vec_dog = wv.word_vec(\"dog/NN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similar to dog vector\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('dog/NN', 1.0000001192092896),\n",
       " ('rottweiler/NN', 0.6149188280105591),\n",
       " ('poodle/NN', 0.5928210020065308),\n",
       " ('dogs/NN', 0.5638971328735352),\n",
       " ('puppy/NN', 0.556917667388916),\n",
       " ('dachshund/NN', 0.5536962747573853),\n",
       " ('pekingese/JJ', 0.5461680293083191),\n",
       " ('pet/VB', 0.5417574048042297),\n",
       " ('bullmastiff/NN', 0.5413403511047363),\n",
       " ('kennel/VB', 0.5349524021148682)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get similar words to vector\n",
    "wv.similar_by_vector(vector=vec_dog, topn=10, restrict_vocab=None)\n",
    "print(\"Similar to dog vector\")\n",
    "wv.most_similar(positive=[vec_dog])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "closer to dog than cat\n",
      "['pet/NN', 'hound/NN', 'kennel/NN', 'puppy/NN', 'kitten/NN', 'canine/JJ', 'beagle/NN', 'retriever/NN', 'dog/VB', 'dachshund/NN', 'feline/JJ', 'leash/NN', 'spaniel/NN', 'sheepdog/NN', 'poodle/NN', 'bichon/NN', 'komondor/NN', 'mastiff/NN', 'pug/NN', 'feline/NN', 'pet/VB', 'longhaired/JJ', 'dogs/JJ', 'rowlf/VB', 'pinscher/NN', 'rottweiler/NN', 'dogs/NN', 'coonhound/NN', 'sniffer/JJ', 'dachshund/VB', 'kennel/VB', 'rottweiler/JJ', 'mangy/JJ', 'euthanization/NN', 'leashed/JJ', 'pug/JJ', 'bullmastiff/NN', 'pekingese/JJ', 'akbash/NN', 'weimaraner/NN', 'pekingese/NN', 'pukin/NN', 'polydactyl/JJ']\n",
      "\n",
      "closer to cat than dog\n",
      "['anthropomorphic/JJ', 'kitten/NN', 'feline/JJ', 'tabby/JJ', 'feline/NN', 'fraggle/NN', 'dogs/JJ', 'tanuki/NN', 'mangy/JJ', 'meow/VB', 'wampus/NN', 'pekingese/JJ', 'nintendogs/JJ', 'scaredy/NN', 'zingano/NN']\n"
     ]
    }
   ],
   "source": [
    "# closer to __ than __\n",
    "print(\"closer to dog than cat\")\n",
    "print(wv.words_closer_than(\"dog/NN\", \"cat/NN\"))\n",
    "print(\"\\ncloser to cat than dog\")\n",
    "print(wv.words_closer_than(\"cat/NN\", \"dog/NN\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalized Vector\n",
    "vec_king_norm = wv.word_vec(\"king/NN\", use_norm=True)\n",
    "# Not normalized vectore\n",
    "vec_king_unnorm = wv.word_vec(\"king/NN\", use_norm=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('martenetz/JJ', 0.25446975231170654),\n",
       " ('chinalink/VB', 0.23597364127635956),\n",
       " ('rosenstreich/JJ', 0.2354564666748047),\n",
       " ('kibbutznikiyot/NN', 0.23487138748168945),\n",
       " ('plastic/NN', 0.23192650079727173),\n",
       " ('unsightliest/JJ', 0.23074199259281158),\n",
       " ('gyoku/JJ', 0.2304389774799347),\n",
       " ('pjp/NN', 0.22816044092178345),\n",
       " ('молива/NN', 0.22780273854732513),\n",
       " ('oppotion/NN', 0.2250170111656189)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wv.most_similar(positive=[vec_king_norm], negative=[vec_king_unnorm])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300,)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get vector shape\n",
    "vec_king_unnorm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "similar to random vector\n",
      "[('qasimov/JJ', 0.2712376117706299), ('schackel/NN', 0.2607859671115875), ('crenex/JJ', 0.25810354948043823), ('市川儀一/VB', 0.25635436177253723), ('格五/NN', 0.25499749183654785), ('ushū/NN', 0.2528385519981384), ('sneese/JJ', 0.24734818935394287), ('homonym/JJ', 0.2461884319782257), ('bodiford/JJ', 0.2461722195148468), ('bako/VB', 0.24406176805496216)]\n",
      "\n",
      " similar to nomalized random vector\n",
      "[('qasimov/JJ', 0.2712376117706299), ('schackel/NN', 0.2607859671115875), ('crenex/JJ', 0.25810354948043823), ('市川儀一/VB', 0.25635436177253723), ('格五/NN', 0.25499749183654785), ('ushū/NN', 0.2528385519981384), ('sneese/JJ', 0.24734818935394287), ('homonym/JJ', 0.2461884319782257), ('bodiford/JJ', 0.2461722195148468), ('bako/VB', 0.24406176805496216)]\n"
     ]
    }
   ],
   "source": [
    "# Generate random vector\n",
    "import numpy as np\n",
    "vec_random = np.random.rand(300,)\n",
    "vec_random_norm = vec_random / vec_random.max(axis=0)\n",
    "print(\"similar to random vector\")\n",
    "print(wv.most_similar(positive=[vec_random]))\n",
    "print(\"\\n similar to nomalized random vector\")\n",
    "print(wv.most_similar(positive=[vec_random_norm]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "similarity from a normalized random vector to normalized vector of king\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('qasimov/JJ', 0.26662397384643555),\n",
       " ('schackel/NN', 0.25880166888237),\n",
       " ('格五/NN', 0.2555546462535858),\n",
       " ('市川儀一/VB', 0.2543610632419586),\n",
       " ('miyatsuko/NN', 0.25367265939712524),\n",
       " ('crenex/JJ', 0.25238728523254395),\n",
       " ('sneese/JJ', 0.2518189549446106),\n",
       " ('tahsildar/NN', 0.2514416575431824),\n",
       " ('sopianae/NN', 0.2507050633430481),\n",
       " ('homonym/JJ', 0.25028181076049805)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get similarity from a random vector and normilized king vector\n",
    "print(\"similarity from a normalized random vector to normalized vector of king\")\n",
    "wv.most_similar(positive=[vec_random_norm,vec_king_norm])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "similarity from a random vector to unormalized vector of king\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('king/NN', 0.8697292804718018),\n",
       " ('uṣur/NN', 0.4679512679576874),\n",
       " ('tukulti/NN', 0.457405686378479),\n",
       " ('neustrium/NN', 0.4550192356109619),\n",
       " ('cnut/NN', 0.4508383274078369),\n",
       " ('hengal/JJ', 0.44895803928375244),\n",
       " ('pileser/NN', 0.4454649090766907),\n",
       " ('shutruk/NN', 0.44528043270111084),\n",
       " ('ninurta/NN', 0.4444091320037842),\n",
       " ('harthacnut/NN', 0.4420572519302368)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get similarity from a random vector and unormalized king vector\n",
    "print(\"similarity from a random vector to unormalized vector of king\")\n",
    "wv.most_similar(positive=[vec_random,vec_king_unnorm])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cosine similarity from a random vector to unormalized vector of king\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-0.04686037])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get cosine similarities from a vector to an array of vectors\n",
    "print(\"cosine similarity from a random vector to unormalized vector of king\")\n",
    "wv.cosine_similarities(vec_random, [vec_king_unnorm])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-04-08 09:50:56,994 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-08 09:50:56,995 : INFO : built Dictionary(12 unique tokens: ['time', 'eps', 'graph', 'minors', 'response']...) from 9 documents (total 29 corpus positions)\n",
      "2019-04-08 09:50:58,110 : INFO : Evaluating word analogies for top 300000 words in the model on datasets/questions-words.txt\n",
      "2019-04-08 09:50:58,160 : INFO : capital-common-countries: 100.0% (2/2)\n",
      "2019-04-08 09:50:58,306 : INFO : Quadruplets with out-of-vocabulary words: 100.0%\n",
      "2019-04-08 09:50:58,308 : INFO : NB: analogies containing OOV words were skipped from evaluation! To change this behavior, use \"dummy4unknown=True\"\n",
      "2019-04-08 09:50:58,308 : INFO : Total accuracy: 100.0% (2/2)\n"
     ]
    }
   ],
   "source": [
    "# Tests analogies based on a text file\n",
    "from gensim.test.utils import datapath\n",
    "analogy_scores = wv.evaluate_word_analogies('datasets/questions-words.txt',dummy4unknown=False)\n",
    "#print(analogy_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distance between dog and cat\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5276151299476624"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The the distance of two words\n",
    "print(\"distance between dog and cat\")\n",
    "wv.distance(\"dog/NN\",\"cat/NN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distance from dog to king and cat\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1.002809 , 0.5276151], dtype=float32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the distance of a word for the list of word\n",
    "print(\"distance from dog to king and cat\")\n",
    "wv.distances(\"dog/NN\",[\"king/NN\",\"cat/NN\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate pairs of words\n",
    "#wv.evaluate_word_pairs(\"datasets/SimLex-999.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['be/VB', 'sentence/NN'] ['be/VB', 'also/RB', 'sentence/NN']\n",
      "0.8849491 \n",
      "\n",
      "['cat/NN', 'be/VB', 'mammal/NN'] ['bird/NN', 'be/VB', 'ave/NN']\n",
      "0.2748915 \n",
      "\n",
      "['cat/NN', 'be/VB', 'mammal/NN'] ['dog/NN', 'be/VB', 'mammal/NN']\n",
      "0.81017876\n"
     ]
    }
   ],
   "source": [
    "# Get sentence similarities\n",
    "\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim.utils import simple_preprocess    \n",
    "\n",
    "def tokemmized(sentence, vocabulary):\n",
    "    tokens = [lem(word) for word in simple_preprocess(sentence)]\n",
    "    return [word for word in tokens if word in vocabulary]   \n",
    "\n",
    "def compute_sentence_similarity(sentence_1, sentence_2, model_wv):\n",
    "    vocabulary = set(model_wv.index2word)\n",
    "    tokens_1 = tokemmized(sentence_1, vocabulary)\n",
    "    tokens_2 = tokemmized(sentence_2, vocabulary)\n",
    "    del vocabulary\n",
    "    print(tokens_1, tokens_2)\n",
    "    return model_wv.n_similarity(tokens_1, tokens_2)\n",
    "\n",
    "similarity = compute_sentence_similarity('this is a sentence', 'this is also a sentence', wv)\n",
    "print(similarity,\"\\n\")\n",
    "\n",
    "similarity = compute_sentence_similarity('the cat is a mammal', 'the bird is a aves', wv)\n",
    "print(similarity,\"\\n\")\n",
    "\n",
    "similarity = compute_sentence_similarity('the cat is a mammal', 'the dog is a mammal', wv)\n",
    "print(similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "france is to france as berlin is to ?\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('berlin/NN', 0.6598570346832275),\n",
       " ('germany/NN', 0.5397100448608398),\n",
       " ('france/NN', 0.49677813053131104),\n",
       " ('osnabrueck/NN', 0.4760308265686035),\n",
       " ('niedersachsen/RB', 0.45274922251701355),\n",
       " ('neukölln/RB', 0.4491945207118988),\n",
       " ('pliezhausen/NN', 0.4466242790222168),\n",
       " ('wuhlheide/VB', 0.4429861903190613),\n",
       " ('meerbusch/NN', 0.4415031671524048),\n",
       " ('filmtage/NN', 0.44115519523620605)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Analogy with not normalized vectors\n",
    "print(\"france is to france as berlin is to ?\")\n",
    "wv.most_similar([wv['france/NN'] - wv['paris/NN'] + wv['berlin/NN']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "france is to france as berlin is to ?\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('paris/NN', 0.7346838712692261),\n",
       " ('france/NN', 0.7047756910324097),\n",
       " ('issy/JJ', 0.5712026357650757),\n",
       " ('nimes/RB', 0.5693367719650269),\n",
       " ('beaubourg/NN', 0.56267249584198),\n",
       " ('chauny/NN', 0.5557336807250977),\n",
       " ('chatou/NN', 0.553068995475769),\n",
       " ('chaville/NN', 0.5530577898025513),\n",
       " ('melun/NN', 0.5504977703094482),\n",
       " ('antibe/NN', 0.5504209399223328)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Analogy with normalized Vector\n",
    "vec_france_norm = wv.word_vec(lem('France'), use_norm=True)\n",
    "vec_paris_norm = wv.word_vec(lem('Paris'), use_norm=True)\n",
    "vec_berlin_norm = wv.word_vec(lem('Berlin'), use_norm=True)\n",
    "vec_germany_norm = wv.word_vec(lem('Germany'), use_norm=True)\n",
    "vec_country_norm = wv.word_vec(lem('country'), use_norm=True)\n",
    "print(\"france is to france as berlin is to ?\")\n",
    "wv.most_similar([vec_france_norm + vec_paris_norm - vec_country_norm])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cosine_similarities of france and paris\n",
      "[0.46068862]\n",
      "cosine_similarities of france and berlin\n",
      "[0.09915119]\n",
      "cosine_similarities of france and country\n",
      "[0.17262796]\n"
     ]
    }
   ],
   "source": [
    "# Cosine Similarities\n",
    "print(\"cosine_similarities of france and paris\")\n",
    "print(wv.cosine_similarities(vec_france_norm, [vec_paris_norm]))\n",
    "print(\"cosine_similarities of france and berlin\")\n",
    "print(wv.cosine_similarities(vec_france_norm, [vec_berlin_norm]))\n",
    "print(\"cosine_similarities of france and country\")\n",
    "print(wv.cosine_similarities(vec_france_norm, [vec_country_norm]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "paris is to france as germany is to ?\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('germany/NN', 0.7783980369567871),\n",
       " ('france/NN', 0.5977498292922974),\n",
       " ('scandinavia/RB', 0.4345003366470337),\n",
       " ('geesthacht/NN', 0.4168975353240967),\n",
       " ('oberflacht/JJ', 0.39931991696357727),\n",
       " ('poland/NN', 0.39648324251174927),\n",
       " ('netherlands/NN', 0.3954917788505554),\n",
       " ('uedem/NN', 0.39445963501930237),\n",
       " ('czechoslovakia/NN', 0.3935864567756653),\n",
       " ('german/NN', 0.3916912376880646)]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Analogy\n",
    "print(\"paris is to france as germany is to ?\")\n",
    "wv.most_similar([wv['france/NN'] + wv['germany/NN'] - wv['paris/NN']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat is to mammal as sparrow is to ?\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('mammal/NN', 0.6350052356719971),\n",
       " ('cat/NN', 0.6204670667648315),\n",
       " ('carnivore/NN', 0.5320420861244202),\n",
       " ('rodent/NN', 0.5169624090194702),\n",
       " ('feline/NN', 0.5153012275695801),\n",
       " ('vertebrate/NN', 0.4844091832637787),\n",
       " ('human/NN', 0.48289990425109863),\n",
       " ('mustelid/NN', 0.47467949986457825),\n",
       " ('carnivorous/JJ', 0.46422073245048523),\n",
       " ('animal/NN', 0.461605966091156)]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Analogy\n",
    "print(\"cat is to mammal as sparrow is to ?\")\n",
    "wv.most_similar([wv['mammal/NN'] - wv['sparrow/NN'] + wv['cat/NN']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grass is to green as sky is to ?\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('green/NN', 0.6720399856567383),\n",
       " ('grass/NN', 0.6147882342338562),\n",
       " ('forbs/JJ', 0.4486176669597626),\n",
       " ('bentgrass/NN', 0.4462357759475708),\n",
       " ('leafy/JJ', 0.4335836172103882),\n",
       " ('cocksfoot/NN', 0.430562287569046),\n",
       " ('herbage/NN', 0.42099571228027344),\n",
       " ('graminoid/NN', 0.4148740768432617),\n",
       " ('esparto/JJ', 0.4135362505912781),\n",
       " ('radish/VB', 0.4130854606628418)]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Analogy\n",
    "print(\"grass is to green as sky is to ?\")\n",
    "wv.most_similar([wv['green/NN'] - wv['sky/NN'] + wv['grass/NN']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "athens is to greece as baghdad is to ?\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('baghdad/NN', 0.7465616464614868),\n",
       " ('baghdad/JJ', 0.5089205503463745),\n",
       " ('basra/NN', 0.4829660654067993),\n",
       " ('najaf/NN', 0.4801582098007202),\n",
       " ('kadhimiya/NN', 0.4733431339263916),\n",
       " ('isfahan/NN', 0.47049379348754883),\n",
       " ('najaf/RB', 0.46331748366355896),\n",
       " ('kirkuk/NN', 0.46281489729881287),\n",
       " ('mashhad/NN', 0.4498487710952759),\n",
       " ('herat/NN', 0.44610485434532166)]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Analogy\n",
    "print(\"athens is to greece as baghdad is to ?\")\n",
    "wv.most_similar([wv['athens/NN'] - wv['greece/NN'] + wv['baghdad/NN']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
